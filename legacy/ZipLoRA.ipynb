{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5636e40f-bcd3-4658-9438-9d7f4bef6235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glom\n",
      "  Downloading glom-23.5.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer\n",
      "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting boltons>=19.3.0 (from glom)\n",
      "  Downloading boltons-24.0.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from glom) (23.1.0)\n",
      "Collecting face==20.1.1 (from glom)\n",
      "  Downloading face-20.1.1-py3-none-any.whl.metadata (868 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.0.1+cu118)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.3.6-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->bitsandbytes) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->bitsandbytes) (15.0.7)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading glom-23.5.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading face-20.1.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boltons-24.0.0-py3-none-any.whl (191 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.6-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, tqdm, safetensors, requests, regex, pyarrow, multidict, kiwisolver, hf_transfer, fsspec, frozenlist, fonttools, dill, cycler, contourpy, boltons, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, matplotlib, huggingface-hub, face, aiosignal, tokenizers, glom, aiohttp, transformers, datasets, accelerate, peft, bitsandbytes\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed accelerate-0.33.0 aiohappyeyeballs-2.3.6 aiohttp-3.10.3 aiosignal-1.3.1 async-timeout-4.0.3 bitsandbytes-0.43.3 boltons-24.0.0 contourpy-1.2.1 cycler-0.12.1 datasets-2.21.0 dill-0.3.8 face-20.1.1 fonttools-4.53.1 frozenlist-1.4.1 fsspec-2024.6.1 glom-23.5.0 hf_transfer-0.1.8 huggingface-hub-0.24.5 kiwisolver-1.4.5 matplotlib-3.9.2 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 peft-0.12.0 pyarrow-17.0.0 pytz-2024.1 regex-2024.7.24 requests-2.32.3 safetensors-0.4.4 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.0 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install glom transformers datasets bitsandbytes accelerate peft hf_transfer matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73d332c-1c04-4f5f-ad57-94420a065481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.0.1+cu118)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=188930485 sha256=f242b686e89e4bd88474ac4ceb7a5b19d738b4e63e2132f50edd7b6f397f8654\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e60b4d-2be8-4b35-ab98-24810be44026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/.hf'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2922b4-f242-4e9f-9a54-7aa2aa8d083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class MergedModulesMixin:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._merged_modules = []\n",
    "\n",
    "    def register_merged_module(self, module):\n",
    "        self._merged_modules.append(module)\n",
    "\n",
    "    def merged_modules(self):\n",
    "        return self._merged_modules\n",
    "\n",
    "    def set_forward_type(self, forward_type):\n",
    "        for module in self._merged_modules:\n",
    "            module.set_forward_type(forward_type)\n",
    "\n",
    "\n",
    "class MergedModel(MergedModulesMixin, AutoModelForCausalLM):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bb19b7-e579-40c6-8b8b-90397a8ead13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6723bd2a5244888b8fd91bc78f49d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99cc4dbb5ea4e83b7d2899b5f18bed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051396650bc4f94a913211dc20a14fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ecb6d5fce243caacf80756e7cf54ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"mistralai/Mistral-7B-v0.1\"\n",
    "MODEL_ID_A = \"augmxnt/shisa-gamma-7b-v1\"\n",
    "MODEL_ID_B = \"WizardLM/WizardMath-7B-V1.1\"\n",
    "MODEL_ID_C = \"GAIR/Abel-7B-002\"\n",
    "\n",
    "base_model = MergedModel.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_A = AutoModelForCausalLM.from_pretrained(MODEL_ID_A, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_B = AutoModelForCausalLM.from_pretrained(MODEL_ID_B, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_C = AutoModelForCausalLM.from_pretrained(MODEL_ID_C, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22222124-85fe-49f3-93ef-bd6fcb507af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "from peft.tuners.lora import QuantLinear\n",
    "\n",
    "def find_embedding(model):\n",
    "    cls = (torch.nn.Embedding)\n",
    "\n",
    "    names = []\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            isinstance(module, cls)\n",
    "        ):\n",
    "            names.append(name)\n",
    "\n",
    "\n",
    "    return names\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = (bnb.nn.Linear4bit, bnb.nn.Linear8bitLt, torch.nn.Linear, QuantLinear)\n",
    "\n",
    "    names = []\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            isinstance(module, cls)\n",
    "            or \"Linear\" in module.__class__.__name__\n",
    "            and module.__class__.__name__ not in (\"LlamaLinearScalingRotaryEmbedding\",)\n",
    "        ):\n",
    "            names.append(name)\n",
    "\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35335d6c-fd57-470f-85ff-56cb9a25c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(base_model) + find_embedding(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b138963-ba2f-4143-8f7e-ecf040eeff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ZipLoRATripleBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.forward_type = \"merge\"\n",
    "\n",
    "    def set_forward_type(self, type: str = \"merge\"):\n",
    "        assert type in [\"merge\", \"weight_1\", \"weight_2\", \"weight_3\"]\n",
    "        self.forward_type = type\n",
    "\n",
    "    def compute_mergers_similarity(self):\n",
    "        sim_12 = F.cosine_similarity(self.merger_1, self.merger_2, dim=0)\n",
    "        sim_13 = F.cosine_similarity(self.merger_1, self.merger_3, dim=0)\n",
    "        sim_23 = F.cosine_similarity(self.merger_2, self.merger_3, dim=0)\n",
    "    \n",
    "        return (sim_12 + sim_13 + sim_23) / 3\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.merger_1.requires_grad = True\n",
    "        self.merger_2.requires_grad = True\n",
    "        self.merger_3.requires_grad = True\n",
    "\n",
    "    def get_ziplora_weight(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9a4562-7b83-456e-b9a7-81e736d4a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZipLoRATripleEmbedding(ZipLoRATripleBase):\n",
    "    def __init__(self, embedding_a, embedding_b, embedding_c, init_merger_value=0.33, init_merger_value_2=0.33, init_merger_value_3=0.33, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert (embedding_a.num_embeddings == embedding_b.num_embeddings == embedding_c.num_embeddings), \"Number of embeddings must match\"\n",
    "        assert (embedding_a.embedding_dim == embedding_b.embedding_dim == embedding_c.embedding_dim), \"Embedding dimensions must match\"\n",
    "\n",
    "        self.num_embeddings = embedding_a.num_embeddings\n",
    "        self.embedding_dim = embedding_a.embedding_dim\n",
    "        self.padding_idx = embedding_a.padding_idx\n",
    "        self.max_norm = embedding_a.max_norm\n",
    "        self.norm_type = embedding_a.norm_type\n",
    "        self.scale_grad_by_freq = embedding_a.scale_grad_by_freq\n",
    "        self.sparse = embedding_a.sparse\n",
    "\n",
    "        self.register_buffer('weight_1', embedding_a.weight.data)\n",
    "        self.register_buffer('weight_2', embedding_b.weight.data)\n",
    "        self.register_buffer('weight_3', embedding_c.weight.data)\n",
    "\n",
    "        self.merger_1 = Parameter(\n",
    "            torch.ones((self.num_embeddings,), device=embedding_a.weight.data.device, dtype=dtype) * init_merger_value\n",
    "        )\n",
    "        self.merger_2 = Parameter(\n",
    "            torch.ones((self.num_embeddings,), device=embedding_b.weight.data.device, dtype=dtype) * init_merger_value_2\n",
    "        )\n",
    "        self.merger_3 = Parameter(\n",
    "            torch.ones((self.num_embeddings,), device=embedding_c.weight.data.device, dtype=dtype) * init_merger_value_3\n",
    "        )\n",
    "        \n",
    "        self.forward_type = \"merge\"\n",
    "        \n",
    "    def get_ziplora_weight(self):\n",
    "        return self.merger_1.unsqueeze(1) * self.weight_1 + self.merger_2.unsqueeze(1) * self.weight_2 + self.merger_3.unsqueeze(1) * self.weight_3\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if self.forward_type == \"merge\":\n",
    "            weight = self.get_ziplora_weight()\n",
    "        elif self.forward_type == \"weight_1\":\n",
    "            weight = self.weight_1\n",
    "        elif self.forward_type == \"weight_2\":\n",
    "            weight = self.weight_2\n",
    "        elif self.forward_type == \"weight_3\":\n",
    "            weight = self.weight_3\n",
    "        else:\n",
    "            raise ValueError(self.forward_type)\n",
    "            \n",
    "        return F.embedding(\n",
    "            input,\n",
    "            weight,\n",
    "            self.padding_idx,\n",
    "            self.max_norm,\n",
    "            self.norm_type,\n",
    "            self.scale_grad_by_freq,\n",
    "            self.sparse\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338441b8-1348-4cdd-b929-83422e16db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZipLoRATripleLinearLayer(ZipLoRATripleBase):\n",
    "    def __init__(self, linear_a, linear_b, linear_c, init_merger_value=0.33, init_merger_value_2=0.33, init_merger_value_3=0.33, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert linear_a.in_features == linear_b.in_features == linear_c.in_features, \"Input features must match\"\n",
    "        assert linear_a.out_features == linear_b.out_features == linear_c.out_features, \"Output features must match\"\n",
    "\n",
    "        self.in_features = linear_a.in_features\n",
    "        self.out_features = linear_a.out_features\n",
    "\n",
    "        self.register_buffer('weight_1', linear_a.weight.data.clone())\n",
    "        self.register_buffer('weight_2', linear_b.weight.data.clone())\n",
    "        self.register_buffer('weight_3', linear_c.weight.data.clone())\n",
    "\n",
    "        if linear_a.bias is not None and linear_b.bias is not None and linear_c.bias is not None:\n",
    "            self.register_buffer('bias1', linear_a.bias.data.clone())\n",
    "            self.register_buffer('bias2', linear_b.bias.data.clone())\n",
    "            self.register_buffer('bias3', linear_c.bias.data.clone())\n",
    "            self.bias_merger1 = nn.Parameter(torch.ones(1, device=linear_a.bias.data.device, dtype=dtype) * init_merger_value)\n",
    "            self.bias_merger2 = nn.Parameter(torch.ones(1, device=linear_b.bias.data.device, dtype=dtype) * init_merger_value_2)\n",
    "            self.bias_merger3 = nn.Parameter(torch.ones(1, device=linear_c.bias.data.device, dtype=dtype) * init_merger_value_3)\n",
    "        else:\n",
    "            self.register_buffer('bias1', None)\n",
    "            self.register_buffer('bias2', None)\n",
    "            self.register_buffer('bias3', None)\n",
    "            self.register_parameter('bias_merger1', None)\n",
    "            self.register_parameter('bias_merger2', None)\n",
    "            self.register_parameter('bias_merger3', None)\n",
    "\n",
    "        # Merger parameters\n",
    "        self.merger_1 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_a.weight.data.device, dtype=dtype) * init_merger_value\n",
    "        )\n",
    "        self.merger_2 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_b.weight.data.device, dtype=dtype) * init_merger_value_2\n",
    "        )\n",
    "        self.merger_3 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_c.weight.data.device, dtype=dtype) * init_merger_value_3\n",
    "        )\n",
    "        \n",
    "        self.forward_type = \"merge\"\n",
    "        \n",
    "    def get_ziplora_weight(self):\n",
    "        return self.merger_1 * self.weight_1 + self.merger_2 * self.weight_2 + self.merger_3 * self.weight_3\n",
    "    \n",
    "    def get_ziplora_bias(self):\n",
    "        if self.bias1 is not None:\n",
    "            return self.bias_merger1 * self.bias1 + self.bias_merger2 * self.bias2 + self.bias_merger3 * self.bias3\n",
    "        return None\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        orig_dtype = hidden_states.dtype\n",
    "        dtype = self.weight_1.dtype\n",
    "        if self.forward_type == \"merge\":\n",
    "            weight = self.get_ziplora_weight()\n",
    "            bias = self.get_ziplora_bias()\n",
    "        elif self.forward_type == \"weight_1\":\n",
    "            weight = self.weight_1\n",
    "            bias = self.bias1\n",
    "        elif self.forward_type == \"weight_2\":\n",
    "            weight = self.weight_2\n",
    "            bias = self.bias2\n",
    "        elif self.forward_type == \"weight_3\":\n",
    "            weight = self.weight_3\n",
    "            bias = self.bias3\n",
    "        else:\n",
    "            raise ValueError(self.forward_type)\n",
    "        \n",
    "        hidden_states = F.linear(hidden_states.to(dtype), weight=weight, bias=bias)\n",
    "        return hidden_states.to(orig_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c6b8d-75c8-4693-8a0c-7fde16b4e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# model_C (GAIR/Abel-7B-002) has a bigger vocab, we truncate the embedding layers\n",
    "\n",
    "truncated_lm_head = nn.Linear(in_features=4096, out_features=32000, bias=False)\n",
    "truncated_embed = nn.Embedding(num_embeddings=32000, embedding_dim=4096)\n",
    "\n",
    "with torch.no_grad():\n",
    "    truncated_lm_head.weight.data = model_C.lm_head.weight.data[:32000, :]\n",
    "    truncated_embed.weight.data = model_C.model.embed_tokens.weight.data[:32000, :]\n",
    "\n",
    "assign_embed = Assign('model.embed_tokens', truncated_embed)\n",
    "assign_lm_head = Assign('lm_head', truncated_lm_head)\n",
    "glom(model_C, assign_embed)\n",
    "glom(model_C, assign_lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efa6820-040c-49c1-924e-e98146cea0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:00<00:00, 641.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from glom import glom, Assign\n",
    "\n",
    "for m in tqdm(modules):\n",
    "    module_a = glom(model_A, m)\n",
    "    module_b = glom(model_B, m)\n",
    "    module_c = glom(model_C, m)\n",
    "\n",
    "    zipped = None\n",
    "\n",
    "    if isinstance(module_a, torch.nn.Embedding):    \n",
    "        zipped = ZipLoRATripleEmbedding(\n",
    "            embedding_a=module_a,\n",
    "            embedding_b=module_b,\n",
    "            embedding_c=module_c,\n",
    "            device=base_model.device,\n",
    "            dtype=module_a.weight.dtype\n",
    "        )\n",
    "    else:\n",
    "        zipped = ZipLoRATripleLinearLayer(\n",
    "            linear_a=module_a,\n",
    "            linear_b=module_b,\n",
    "            linear_c=module_c,\n",
    "            device=base_model.device,\n",
    "            dtype=module_a.weight.dtype\n",
    "        )\n",
    "\n",
    "    assign = Assign(m, zipped)\n",
    "    glom(base_model, assign)\n",
    "    base_model.register_merged_module(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea86570-bffd-43ba-a310-fe99674714a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Abraham Lincoln is considered by many to be the most famous president in U.S. history. He led the country through the Civil War and issued the Emancipation Proclamation, which ended slavery in the Confederate states. Lincoln is also known for delivering the Gettysburg Address, one of\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model=base_model, task='text-generation', tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Who is the most famous president?\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "print(generator(prompt, do_sample=True, max_new_tokens=64)[0]['generated_text'][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984cad48-0940-4c37-96e2-a7d4dae270d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model_A.cpu()\n",
    "model_B.cpu()\n",
    "model_C.cpu()\n",
    "\n",
    "del model_A, model_B, model_C\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f59fd4d-f5dd-46dc-9c52-2844aa475ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{%- set ns = namespace(found=false) -%}\\n{%- for message in messages -%}\\n    {%- if message['role'] == 'system' -%}\\n        {%- set ns.found = true -%}\\n    {%- endif -%}\\n{%- endfor -%}\\n{%- if not ns.found -%}\\n    {{- '' + 'Below is an instruction that describes a task. Write a response that appropriately completes the request.' + '\\\\n\\\\n' -}}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if message['role'] == 'system' -%}\\n        {{- '' + message['content'] + '\\\\n\\\\n' -}}\\n    {%- else -%}\\n        {%- if message['role'] == 'user' -%}\\n            {{-'### Instruction:\\\\n' + message['content'] + '\\\\n\\\\n'-}}\\n        {%- else -%}\\n            {{-'### Response:\\\\n' + message['content'] + '\\\\n\\\\n' -}}\\n        {%- endif -%}\\n    {%- endif -%}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n    {{-'### Response:\\\\n'-}}\\n{%- endif -%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b87fdb8-b840-4b7c-ba75-ac36909e7aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa24bde12034032a2c8db8e075e2822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bc96919a184693abfb5d82f5d43b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37054a0c26a47868a0d8e0a910aafa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1729 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_A = load_dataset(\"p1atdev/ichikara-instruction\", '20231115-1').rename_column(\"text\", \"instruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16f4cd7-6076-4c17-9d92-50b74fb0aa9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c98afd4a939470a8a76d79a47c2ea1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1729 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "templated_dataset_A = dataset_A.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['instruction']}, {'role': 'assistant', 'content': row['output'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a93050c-1f24-4a4f-8a1f-d34fad499791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680ffca84e474ec4a237b83a7b9a4ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82be42c873ad4b1e92b6352d465ee075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437b066ed0b54e29af919340b76c6d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/200035 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_B = load_dataset(\"microsoft/orca-math-word-problems-200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c4a9cd3-b204-4a75-b97b-af15ca6893f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d525962217c14ff88dad09f425468964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200035 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "templated_dataset_B = dataset_B.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['question']}, {'role': 'assistant', 'content': row['answer'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeab0566-f0d8-4280-b75d-7dd2994a4fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9af7b0c3ec4072ac93ba6b795cf70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6e396be2dd41998ebdc47b505229bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/396M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f41a9db2cef4173b6715420f9f465e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/395000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_C = load_dataset(\"meta-math/MetaMathQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a8a0702-057e-4337-b805-b4cded87da30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81935b5b1006454ab6d55177a4b721e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/395000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "templated_dataset_C = dataset_C.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['query']}, {'role': 'assistant', 'content': row['response'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb283f9-3fea-4629-86c1-5d549f1df656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in base_model.modules():\n",
    "    if isinstance(module, ZipLoRATripleLinearLayer) or isinstance(module, ZipLoRATripleEmbedding):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5419cb7f-ba7a-4f96-be45-d3e40b1e5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ziplora_loss_for_lm(model, prompt_a, prompt_b, prompt_c, lambda_coef=0.01, temperature=2.0):\n",
    "    # Tokenize inputs\n",
    "    batch = tokenizer([prompt_a, prompt_b, prompt_c], padding=\"max_length\", truncation=True, max_length=4096, return_tensors='pt')\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    # Split inputs for a, b, and c\n",
    "    input_a = input_ids[0].to(model.device)\n",
    "    input_b = input_ids[1].to(model.device)\n",
    "    input_c = input_ids[2].to(model.device)\n",
    "\n",
    "    # Prepare labels (shifted input_ids)\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[attention_mask == 0] = -100  # Set padding token positions to -100\n",
    "\n",
    "    labels_a = labels[0].to(model.device)\n",
    "    labels_b = labels[1].to(model.device)\n",
    "    labels_c = labels[2].to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get logits from model_A\n",
    "        model.set_forward_type('weight_1')\n",
    "        original_logits_a = model(input_ids=input_a.unsqueeze(0), labels=labels_a.unsqueeze(0)).logits\n",
    "\n",
    "        # Get logits from model_B\n",
    "        model.set_forward_type('weight_2')\n",
    "        original_logits_b = model(input_ids=input_b.unsqueeze(0), labels=labels_b.unsqueeze(0)).logits\n",
    "\n",
    "        # Get logits from model_C\n",
    "        model.set_forward_type('weight_3')\n",
    "        original_logits_c = model(input_ids=input_c.unsqueeze(0), labels=labels_c.unsqueeze(0)).logits\n",
    "\n",
    "    model.set_forward_type('merge')\n",
    "\n",
    "    # Get logits from merged model for all inputs\n",
    "    merged_logits_a = model(input_ids=input_a.unsqueeze(0), labels=labels_a.unsqueeze(0)).logits\n",
    "    merged_logits_b = model(input_ids=input_b.unsqueeze(0), labels=labels_b.unsqueeze(0)).logits\n",
    "    merged_logits_c = model(input_ids=input_c.unsqueeze(0), labels=labels_c.unsqueeze(0)).logits\n",
    "\n",
    "    # Calculate losses (KL divergence between merged and original logits)\n",
    "    loss_a = F.kl_div(\n",
    "        F.log_softmax(merged_logits_a / temperature, dim=-1),\n",
    "        F.softmax(original_logits_a / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_a)\n",
    "    \n",
    "    loss_b = F.kl_div(\n",
    "        F.log_softmax(merged_logits_b / temperature, dim=-1),\n",
    "        F.softmax(original_logits_b / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_b)\n",
    "    \n",
    "    loss_c = F.kl_div(\n",
    "        F.log_softmax(merged_logits_c / temperature, dim=-1),\n",
    "        F.softmax(original_logits_c / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_c)\n",
    "    \n",
    "    # Calculate similarity loss to encourage diversity between mergers\n",
    "    similarity_loss = torch.tensor(0.0)\n",
    "    for module in base_model.modules():\n",
    "        if isinstance(module, ZipLoRATripleLinearLayer) or isinstance(module, ZipLoRATripleEmbedding):\n",
    "            similarity_loss += module.compute_mergers_similarity().to(similarity_loss.device)\n",
    "    \n",
    "    # Combine losses\n",
    "    total_loss = loss_a + loss_b + loss_c + lambda_coef * similarity_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814fdc8-6bda-4fc7-9fc8-ae0f2a5c4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtHElEQVR4nO3dd3hUVf4G8PfOJDOpk15JSEIooUY6AWkCAouKZVERFewKrGUtK7s/lcWCvSsuNuyKDRTpVZDee0gjCel9Uqfe3x8zczOTAiFMcsPk/TxPHpM7986cuQTn5ZzvOUcQRVEEERERkYtQyN0AIiIiImdiuCEiIiKXwnBDRERELoXhhoiIiFwKww0RERG5FIYbIiIicikMN0RERORSGG6IiIjIpTDcEBERkUthuCGiNjdnzhzExsa26tqFCxdCEATnNoiIXBrDDVEnJghCi762bt0qd1NlMWfOHPj4+MjdDCK6SAL3liLqvL7++muHn7/88kts2LABX331lcPxSZMmISwsrNWvYzAYYDaboVarL/pao9EIo9EIDw+PVr9+a82ZMwc//fQTqqqq2v21iaj13ORuABHJ5/bbb3f4effu3diwYUOj4w3V1NTAy8urxa/j7u7eqvYBgJubG9zc+L8qImo5DksR0XmNGzcO/fr1w4EDBzBmzBh4eXnh3//+NwBg5cqVmDZtGiIjI6FWqxEfH4/nn38eJpPJ4Tka1tycPXsWgiDg9ddfx9KlSxEfHw+1Wo2hQ4di3759Dtc2VXMjCALmz5+PFStWoF+/flCr1ejbty/Wrl3bqP1bt27FkCFD4OHhgfj4ePzvf/9zeh3Pjz/+iMGDB8PT0xPBwcG4/fbbkZOT43BOfn4+7rrrLkRFRUGtViMiIgLTp0/H2bNnpXP279+PyZMnIzg4GJ6enoiLi8Pdd9/ttHYSdRb85xARXVBJSQmmTp2KW2+9Fbfffrs0RLVs2TL4+Pjgn//8J3x8fLB582Y8++yz0Gq1eO211y74vN9++y0qKyvxwAMPQBAEvPrqq7jxxhuRnp5+wd6eHTt24JdffsHcuXPh6+uLd999FzfddBOysrIQFBQEADh06BCmTJmCiIgI/Pe//4XJZMKiRYsQEhJy6TfFatmyZbjrrrswdOhQLF68GAUFBXjnnXfw119/4dChQ/D39wcA3HTTTThx4gT+8Y9/IDY2FoWFhdiwYQOysrKkn6+++mqEhITg6aefhr+/P86ePYtffvnFaW0l6jREIiKrefPmiQ3/tzB27FgRgPjRRx81Or+mpqbRsQceeED08vIS6+rqpGOzZ88WY2JipJ8zMjJEAGJQUJBYWloqHV+5cqUIQPz999+lY88991yjNgEQVSqVmJqaKh07cuSICEB87733pGPXXnut6OXlJebk5EjHUlJSRDc3t0bP2ZTZs2eL3t7ezT6u1+vF0NBQsV+/fmJtba10fNWqVSIA8dlnnxVFURTLyspEAOJrr73W7HP9+uuvIgBx3759F2wXEZ0fh6WI6ILUajXuuuuuRsc9PT2l7ysrK1FcXIzRo0ejpqYGp0+fvuDz3nLLLQgICJB+Hj16NAAgPT39gtdOnDgR8fHx0s8DBgyARqORrjWZTNi4cSOuv/56REZGSud1794dU6dOveDzt8T+/ftRWFiIuXPnOhQ8T5s2DQkJCfjjjz8AWO6TSqXC1q1bUVZW1uRz2Xp4Vq1aBYPB4JT2EXVWDDdEdEFdunSBSqVqdPzEiRO44YYb4OfnB41Gg5CQEKkYuaKi4oLP27VrV4efbUGnuQBwvmtt19uuLSwsRG1tLbp3797ovKaOtUZmZiYAoFevXo0eS0hIkB5Xq9V45ZVXsGbNGoSFhWHMmDF49dVXkZ+fL50/duxY3HTTTfjvf/+L4OBgTJ8+HZ9//jl0Op1T2krUmTDcENEF2ffQ2JSXl2Ps2LE4cuQIFi1ahN9//x0bNmzAK6+8AgAwm80XfF6lUtnkcbEFK1RcyrVyePTRR3HmzBksXrwYHh4eeOaZZ9C7d28cOnQIgKVI+qeffsKuXbswf/585OTk4O6778bgwYM5FZ3oIjHcEFGrbN26FSUlJVi2bBkeeeQRXHPNNZg4caLDMJOcQkND4eHhgdTU1EaPNXWsNWJiYgAAycnJjR5LTk6WHreJj4/H448/jvXr1+P48ePQ6/V44403HM4ZMWIEXnzxRezfvx/ffPMNTpw4ge+//94p7SXqLBhuiKhVbD0n9j0ler0eH374oVxNcqBUKjFx4kSsWLECubm50vHU1FSsWbPGKa8xZMgQhIaG4qOPPnIYPlqzZg1OnTqFadOmAbCsC1RXV+dwbXx8PHx9faXrysrKGvU6XXHFFQDAoSmii8Sp4ETUKiNHjkRAQABmz56Nhx9+GIIg4KuvvupQw0ILFy7E+vXrMWrUKDz00EMwmUx4//330a9fPxw+fLhFz2EwGPDCCy80Oh4YGIi5c+filVdewV133YWxY8di5syZ0lTw2NhYPPbYYwCAM2fOYMKECbj55pvRp08fuLm54ddff0VBQQFuvfVWAMAXX3yBDz/8EDfccAPi4+NRWVmJjz/+GBqNBn/729+cdk+IOgOGGyJqlaCgIKxatQqPP/44/u///g8BAQG4/fbbMWHCBEyePFnu5gEABg8ejDVr1uCJJ57AM888g+joaCxatAinTp1q0WwuwNIb9cwzzzQ6Hh8fj7lz52LOnDnw8vLCyy+/jH/961/w9vbGDTfcgFdeeUWaARUdHY2ZM2di06ZN+Oqrr+Dm5oaEhAQsX74cN910EwBLQfHevXvx/fffo6CgAH5+fhg2bBi++eYbxMXFOe2eEHUG3FuKiDqd66+/HidOnEBKSorcTSGiNsCaGyJyabW1tQ4/p6SkYPXq1Rg3bpw8DSKiNseeGyJyaREREZgzZw66deuGzMxMLFmyBDqdDocOHUKPHj3kbh4RtQHW3BCRS5syZQq+++475OfnQ61WIykpCS+99BKDDZELY88NERERuRTW3BAREZFLYbghIiIil9Lpam7MZjNyc3Ph6+sLQRDkbg4RERG1gCiKqKysRGRkJBSK8/fNdLpwk5ubi+joaLmbQURERK2QnZ2NqKio857T6cKNr68vAMvN0Wg0MreGiIiIWkKr1SI6Olr6HD+fThdubENRGo2G4YaIiOgy05KSEhYUExERkUthuCEiIiKXwnBDRERELoXhhoiIiFwKww0RERG5FIYbIiIicikMN0RERORSGG6IiIjIpTDcEBERkUthuCEiIiKXwnBDRERELoXhhoiIiFwKw42TiaKIWr1J7mYQERF1Wgw3Tvb8qlO4YtF6pBVVyd0UIiKiTknWcBMbGwtBEBp9zZs3r8nzly1b1uhcDw+Pdm71+R3KLoPOaMapPK3cTSEiIuqU3OR88X379sFkqh/COX78OCZNmoQZM2Y0e41Go0FycrL0syAIbdrGi2UyiwAAvdEsc0uIiIg6J1nDTUhIiMPPL7/8MuLj4zF27NhmrxEEAeHh4W3dtFYzmCzhRsdwQ0REJIsOU3Oj1+vx9ddf4+677z5vb0xVVRViYmIQHR2N6dOn48SJE+d9Xp1OB61W6/DVlkxmS6hhzw0REZE8Oky4WbFiBcrLyzFnzpxmz+nVqxc+++wzrFy5El9//TXMZjNGjhyJc+fONXvN4sWL4efnJ31FR0e3QevrGTksRUREJCtBFEVR7kYAwOTJk6FSqfD777+3+BqDwYDevXtj5syZeP7555s8R6fTQafTST9rtVpER0ejoqICGo3mktvd0NjXtiCzpAZPTu6FeeO7O/35iYiIOiOtVgs/P78WfX7LWnNjk5mZiY0bN+KXX365qOvc3d0xcOBApKamNnuOWq2GWq2+1Ca2mJE1N0RERLLqEMNSn3/+OUJDQzFt2rSLus5kMuHYsWOIiIhoo5ZdPCNrboiIiGQle7gxm834/PPPMXv2bLi5OXYk3XnnnViwYIH086JFi7B+/Xqkp6fj4MGDuP3225GZmYl77723vZvdLE4FJyIikpfsw1IbN25EVlYW7r777kaPZWVlQaGoz19lZWW47777kJ+fj4CAAAwePBg7d+5Enz592rPJ52UrKNYZuQUDERGRHDpMQXF7uZiCpNbo/9w6VOqMmDE4Cq/NSHT68xMREXVGF/P5LfuwlKuRpoKbOCxFREQkB4YbJ2NBMRERkbwYbpyMi/gRERHJi+HGicxmEbYKJg5LERERyYPhxolsvTYAF/EjIiKSC8ONE5kYboiIiGTHcONEBnN9oGHNDRERkTwYbpzIZKrvudFzET8iIiJZMNw4kX3NDQuKiYiI5MFw40T2NTccliIiIpIHw40TGVlzQ0REJDuGGycymthzQ0REJDeGGydizQ0REZH8GG6cyL7mxmASYTZ3qg3XiYiIOgSGGyeyr7kB2HtDREQkB4YbJzI16KnhKsVERETtj+HGiQwmx3DDomIiIqL2x3DjRA17bjgsRURE1P4YbpyoUc0Ne26IiIjaHcONEzXquWG4ISIiancMN05kbFRQzM0ziYiI2hvDjRMZWVBMREQkO4YbJzKx5oaIiEh2DDdO1GhYirOliIiI2h3DjROxoJiIiEh+DDdOxJobIiIi+THcOBHXuSEiIpIfw40TNZ4KznBDRETU3hhunKhxzQ3XuSEiImpvDDdO1KjmhrOliIiI2h3DjRNxthQREZH8GG6cyMCCYiIiItkx3DiRycRF/IiIiOTGcONEDWdLseeGiIio/THcOFHDmhtOBSciImp/DDdOxJobIiIi+THcOJGt5sZdKQBguCEiIpIDw40T2WpuvFRuABhuiIiI5MBw40S2mhtvlRIAF/EjIiKSA8ONE9l6bjxt4YY9N0RERO2O4caJjNaeGtuwlI57SxEREbU7hhsnsg1L+agt4abWwHBDRETU3hhunMg2LOXv5Q4AqKozytkcIiKiTonhxolMDcONjj03RERE7Y3hxomM1kX8/L1UAIAqnUHO5hAREXVKDDdOZLQu4ufvaem5qTOYYeB0cCIionbFcONEtpobP2u4AYBqHetuiIiI2pOs4SY2NhaCIDT6mjdvXrPX/Pjjj0hISICHhwf69++P1atXt2OLz89Wc+PhroSHu+XWVrKomIiIqF3JGm727duHvLw86WvDhg0AgBkzZjR5/s6dOzFz5kzcc889OHToEK6//npcf/31OH78eHs2u1m2mhs3pQAfta2omOGGiIioPckabkJCQhAeHi59rVq1CvHx8Rg7dmyT57/zzjuYMmUKnnzySfTu3RvPP/88Bg0ahPfff7+dW940W8+Nm0KAj9qySjHDDRERUfvqMDU3er0eX3/9Ne6++24IgtDkObt27cLEiRMdjk2ePBm7du1qjyZekMFaUKxUKODjYVnIj+GGiIiofbnJ3QCbFStWoLy8HHPmzGn2nPz8fISFhTkcCwsLQ35+frPX6HQ66HQ66WetVnvJbW2OY8+NNdyw5oaIiKhddZiem08//RRTp05FZGSkU5938eLF8PPzk76io6Od+vz2bLOllArW3BAREcmlQ4SbzMxMbNy4Effee+95zwsPD0dBQYHDsYKCAoSHhzd7zYIFC1BRUSF9ZWdnO6XNTTHZFRT7erDnhoiISA4dItx8/vnnCA0NxbRp0857XlJSEjZt2uRwbMOGDUhKSmr2GrVaDY1G4/DVVozSsJRCGpaqZM8NERFRu5I93JjNZnz++eeYPXs23NwcS4DuvPNOLFiwQPr5kUcewdq1a/HGG2/g9OnTWLhwIfbv34/58+e3d7ObZDTZDUux54aIiEgWsoebjRs3IisrC3fffXejx7KyspCXlyf9PHLkSHz77bdYunQpEhMT8dNPP2HFihXo169feza5WU0WFHN/KSIionYl+2ypq6++GqIoNvnY1q1bGx2bMWNGs4v8yc22iJ/SIdyw54aIiKg9yd5z40psPTfuSoVduDHJ2SQiIqJOh+HGiRymgks1NxyWIiIiak8MN05kKyh2Uwjw5bAUERGRLBhunMih5oazpYiIiGTBcONETdXccJ0bIiKi9sVw40RN1tzojM3OBiMiIiLnY7hxErNZhC3DWGpuLHtLiSJQo+eMKSIiovbCcOMkBmu9DQAolQI83BVQKgQAQDWHpoiIiNoNw42T2OptAEvPjSAI8FYpAbDuhoiIqD0x3DiJ0SHcWG6rr4dlaKqSM6aIiIjaDcONk5hMjj03AOBrLSqu5EJ+RERE7YbhxklsPTeCACis4Ubjaem5qahluCEiImovDDdOYlvAz9ZrAwB+DDdERETtjuHGSWxbLyjtwo3GWnOjrWXNDRERUXthuHESaXViRf0tZc8NERFR+2O4cRJpdWIlh6WIiIjkxHDjJLaeG/uaG42nZbaUlrOliIiI2g3DjZMYTPU7gtvYem607LkhIiJqNww3TlLfc8OaGyIiIjkx3DiJrebGTWk/LMWeGyIiovbmJncDXEVcsDfenTkQHm7suSEiIpITw42TBHqrcF1ipMMxqeamzghRFCEIQlOXEhERkRNxWKoN2RbxM5lFVOtNMreGiIioc2C4aUMe7gqolJZbzKEpIiKi9sFw04YEQZDWuqmoYbghIiJqDww3bUyaMcWF/IiIiNoFw00b44wpIiKi9sVw08ZsRcUMN0RERO2D4aaNcQsGIiKi9sVw08YYboiIiNoXw00bk2ZLMdwQERG1C4abNma/SjERERG1PYabNubvpQIAlFTrZW4JERFR58Bw08ZCfdUAgEJtncwtISIi6hwYbtpYmMYDAFBYqZO5JURERJ0Dw00bs4Wb0mo9dEZunklERNTWGG7aWICXO9yVAgCgiL03REREbY7hpo0JgoBQXw5NERERtReGm3YQqmFRMRERUXthuGkHYdaemwIte26IiIjaGsNNOwiz9twUsOeGiIiozTHctINQTgcnIiJqNww37cA2HZw9N0RERG2P4aYd1K9SzJ4bIiKitsZw0w5sPTfJBZVIWrwJq47mytwiIiIi18Vw0w5sBcUAkFdRhyVb02RsDRERkWtjuGkHfp7uDj+fyNUirahKptYQERG5NoabdiAIAt6YkYj547tjdI9gAMBvhzk0RURE1BZkDzc5OTm4/fbbERQUBE9PT/Tv3x/79+9v9vytW7dCEIRGX/n5+e3Y6ot30+AoPDG5F24c1AUA8PuRXIiiKHOriIiIXI+bnC9eVlaGUaNGYfz48VizZg1CQkKQkpKCgICAC16bnJwMjUYj/RwaGtqWTXWaib3DAADpxdXQ1hkbDVkRERHRpZE13LzyyiuIjo7G559/Lh2Li4tr0bWhoaHw9/dvo5a1HV8Pd3i4K1BnMENba2C4ISIicjJZh6V+++03DBkyBDNmzEBoaCgGDhyIjz/+uEXXXnHFFYiIiMCkSZPw119/NXueTqeDVqt1+JKbLdBU1BpkbgkREZHrkTXcpKenY8mSJejRowfWrVuHhx56CA8//DC++OKLZq+JiIjARx99hJ9//hk///wzoqOjMW7cOBw8eLDJ8xcvXgw/Pz/pKzo6uq3eTovZwo2W4YaIiMjpBFHGqlaVSoUhQ4Zg586d0rGHH34Y+/btw65du1r8PGPHjkXXrl3x1VdfNXpMp9NBp6tfGVir1SI6OhoVFRUONTvt6e9LdmJ/ZhmWzBqEqf0jZGkDERHR5USr1cLPz69Fn9+y9txERESgT58+Dsd69+6NrKysi3qeYcOGITU1tcnH1Go1NBqNw5fcpJ6bOvbcEBEROZus4WbUqFFITk52OHbmzBnExMRc1PMcPnwYERGXTw8Ia26IiIjajqyzpR577DGMHDkSL730Em6++Wbs3bsXS5cuxdKlS6VzFixYgJycHHz55ZcAgLfffhtxcXHo27cv6urq8Mknn2Dz5s1Yv369XG/jomkYboiIiNqMrOFm6NCh+PXXX7FgwQIsWrQIcXFxePvttzFr1izpnLy8PIdhKr1ej8cffxw5OTnw8vLCgAEDsHHjRowfP16Ot9AqGqmg2ChzS4iIiFyPrAXFcriYgqS28umODDy/6iSuS4zEuzMHytIGIiKiy8llU1DcWWk8LB1mHJYiIiJyPoYbGXC2FBERUdthuJEBC4qJiIjaDsONDLhCMRERUdthuJGBn91sqU5Wz01ERNTmGG5kYBuW0pvMqDOYZW4NERGRa2G4kYG3SgmlQgDAomIiIiJnY7iRgSAI3IKBiIiojTDcyIRr3RAREbUNhhuZcMYUERFR22C4kQnXuiEiImobDDcyYbghIiJqGww3MrENS5XXMNwQERE5E8ONTEJ91QCAwkqdzC0hIiJyLQw3MgnXeAAACrR1MreEiIjItTDcyCTMzxJu8isYboiIiJyJ4UYmtp6bfPbcEBERORXDjUxs4aa0Wg+d0SRza4iIiFwHw41M/L3coXKz3P5CLYuKiYiInIXhRiaCIHBoioiIqA0w3MhICjcsKiYiInIahhsZ2WZMcTo4ERGR8zDcyChcY1nIjz03REREzsNwI6Mw1twQERE5HcONjMI5LEVEROR0DDcy4mwpIiIi52O4kVG43RYMJrMoc2uIiIhcA8ONjMI1HnBTCDCYRA5NEREROUmrwk12djbOnTsn/bx37148+uijWLp0qdMa1hm4KRXoEuAJAMgqrZG5NURERK6hVeHmtttuw5YtWwAA+fn5mDRpEvbu3Yv//Oc/WLRokVMb6Oq6BnoBYLghIiJyllaFm+PHj2PYsGEAgOXLl6Nfv37YuXMnvvnmGyxbtsyZ7XN50dZwk81wQ0RE5BStCjcGgwFqtWUBuo0bN+K6664DACQkJCAvL895resE2HNDRETkXK0KN3379sVHH32E7du3Y8OGDZgyZQoAIDc3F0FBQU5toKtjuCEiInKuVoWbV155Bf/73/8wbtw4zJw5E4mJiQCA3377TRquopbpymEpIiIip3JrzUXjxo1DcXExtFotAgICpOP3338/vLy8nNa4zsBWc1NcpUe1zghvdav+SIiIiMiqVT03tbW10Ol0UrDJzMzE22+/jeTkZISGhjq1ga7Oz9Mdfp7uAIDsMvbeEBERXapWhZvp06fjyy+/BACUl5dj+PDheOONN3D99ddjyZIlTm1gZxATZK27KWG4ISIiulStCjcHDx7E6NGjAQA//fQTwsLCkJmZiS+//BLvvvuuUxvYGcQFewMAjudqZW4JERHR5a9V4aampga+vr4AgPXr1+PGG2+EQqHAiBEjkJmZ6dQGdgaj4oMBANuSC2VuCRER0eWvVeGme/fuWLFiBbKzs7Fu3TpcffXVAIDCwkJoNBqnNrAzGNsrBABw5FwFiqt0MreGiIjo8taqcPPss8/iiSeeQGxsLIYNG4akpCQAll6cgQMHOrWBnUGYxgN9Iiyh8M8zRTK3hoiI6PLWqnDz97//HVlZWdi/fz/WrVsnHZ8wYQLeeustpzWuMxmfYOm9+fngOZRW62VuDRER0eVLEEVRvJQnsO0OHhUV5ZQGtTWtVgs/Pz9UVFR0qCG0I9nlmP7BXwAAL5USv82/Et1DfWRuFRERUcdwMZ/freq5MZvNWLRoEfz8/BATE4OYmBj4+/vj+eefh9lsblWjO7vEaH8smTUI4RoP1OhNOJRVJneTiIiILkutWg73P//5Dz799FO8/PLLGDVqFABgx44dWLhwIerq6vDiiy86tZGdxdT+Edh4qhA/HzyHIhYWExERtUqrws0XX3yBTz75RNoNHAAGDBiALl26YO7cuQw3lyDE17LbeqGW4YaIiKg1WjUsVVpaioSEhEbHExISUFpaesmN6sxCreGGPTdERESt06pwk5iYiPfff7/R8ffffx8DBgy4qOfKycnB7bffjqCgIHh6eqJ///7Yv3//ea/ZunUrBg0aBLVaje7du2PZsmUX9Zodma3npog9N0RERK3SqmGpV199FdOmTcPGjRulNW527dqF7OxsrF69usXPU1ZWhlGjRmH8+PFYs2YNQkJCkJKS4rDTeEMZGRmYNm0aHnzwQXzzzTfYtGkT7r33XkRERGDy5MmteTsdin3PzfJ92diTUYrFN/aHyq1VOZSIiKjTafVU8NzcXHzwwQc4ffo0AKB37964//778cILL2Dp0qUteo6nn34af/31F7Zv397i1/3Xv/6FP/74A8ePH5eO3XrrrSgvL8fatWsveH1HnQpuk15Uhave2AZvlRIe7kqUVOvxyZ1DMLFPmNxNIyIikk2bTwUHgMjISLz44ov4+eef8fPPP+OFF15AWVkZPv300xY/x2+//YYhQ4ZgxowZCA0NxcCBA/Hxxx+f95pdu3Zh4sSJDscmT56MXbt2NXm+TqeDVqt1+OrIQjUeAIBqvQkl1sX8juVUyNkkIiKiy4qsYx3p6elYsmQJevTogXXr1uGhhx7Cww8/jC+++KLZa/Lz8xEW5tiLERYWBq1Wi9ra2kbnL168GH5+ftJXdHS009+HM3mrlPB0VzocY7ghIiJqOVnDjdlsxqBBg/DSSy9h4MCBuP/++3Hffffho48+ctprLFiwABUVFdJXdna20567LQiCgFCN2uEYww0REVHLyRpuIiIi0KdPH4djvXv3RlZWVrPXhIeHo6CgwOFYQUEBNBoNPD09G52vVquh0Wgcvjo6W1GxTVGlDgXaOplaQ0REdHm5qNlSN95443kfLy8vv6gXHzVqFJKTkx2OnTlzBjExMc1ek5SU1GhG1oYNG6RZW64gpEG4AYCj5yowqY+HDK0hIiK6vFxUz4197UpTXzExMbjzzjtb/HyPPfYYdu/ejZdeegmpqan49ttvsXTpUsybN086Z8GCBQ7P+eCDDyI9PR1PPfUUTp8+jQ8//BDLly/HY489djFvpUML9a0PMfEh3gAch6bqDCYYTNzDi4iIqCkX1XPz+eefO/XFhw4dil9//RULFizAokWLEBcXh7fffhuzZs2SzsnLy3MYpoqLi8Mff/yBxx57DO+88w6ioqLwySefuMQaNzb2PTc3DorCa+uS8eeZIvxzUk9U64yY9u52CIKADY+NgZuS698QERHZa9Uifs50zTXX4Jprrmn28aZWHx43bhwOHTrUhq2Sly3chGnUuHlINN7eeAaHs8tx7FwFdqeX4GxJDQCgtFovTR0nIiIiC/6zvwMaEOUHQQBGxgcjxFeNaf0jAABLt6fj0x0Z0nm2dXCIiIionuw9N9RYQrgGe/89EQFe7gCAO0fGYsXhXPx+JNfhvDKGGyIiokbYc9NBhfiqpXqagdH++Fv/cCgVAlR2NTbsuSEiImqMPTeXAUEQ8OGswQAAURTx0NcHsfZEPspqGG6IiIgaYs/NZUYQBAT6qAAAJVUMN0RERA0x3FyGAr0s4YY9N0RERI0x3FyGAr2tPTesuSEiImqE4eYyFGQdluJsKSIiosYYbi5DAdZhqVKGGyIiokYYbi5DtmEphhsiIqLGGG4uQ7ZwU1ajhyiKMreGiIioY2G4uQzZwo3BJEJbZ5S5NURERB0Lw81lyMNdCS+VEoClqFhnNCGloJK9OERERGC4uWzZTwdfvPo0Jr31JzadKpS5VURERPJjuLlMSXU31Xr8lVoMADidr5WzSURERB0Cw81lyhZucsprkVZUBQAoqtTJ2SQiIqIOgeHmMmULNztSi2G2ltoUc68pIiIihpvLVXyIDwBg8+n6Ohv23BARETHcXLb+1j8CAGAy18+QKq5iuCEiImK4uUzFBXujb6TG4Rh7boiIiBhuLmvXDIh0+LlSZ0SdwSRTa4iIiDoGhpvL2LWJEVC7KdDF3xMqN8sfJXtviIios2O4uYxFBXjh939ciR8eGIEQHzUAoIh1N0RE1Mm5yd0AujQ9w3wBAMG+auSU16KYPTdERNTJsefGRbDnhoiIyILhxkWE+FoW9UspqMKOlGKZW0NERCQfhhsXYeu5WbbzLG7/dA92pZXI3CIiIiJ5MNy4iBBftcPPu9IZboiIqHNiuHERQT6O4aaosg4AUFKlw5M/HsH+s6VyNIuIiKjdMdy4iEh/T4efM4qrAQB/HMvDjwfOYcnWNDmaRURE1O4YblxEYpQfFk3viwVTEwAAZ4trAAC55ZYenHxtnWxtIyIiak8MNy5CEATcmRSLW4ZGA7CEmRq9EQXWUMOVi4mIqLNguHEx/l4q+Hu5A7D03uRXWMJNcZXOYQdxIiIiV8Vw44Ligr0BAGdLqqWeG7MIlFSz94aIiFwfw40LiguyhJuM4mqHWptCLcMNERG5PoYbFxRr7bk5dq4CNXqTdJx1N0RE1Bkw3Lgg27DU7gzHhfwYboiIqDNguHFB/br4AQDKawwOxwsrOR2ciIhcH8ONC4oN8kKAdcaUvUL23BARUSfAcOOCBEHAwK4Bdj9b/suCYiIi6gwYblzUwGh/6XtbDQ6HpYiIqDNguHFRg2Lqe24GWGtwiqp0yCmvhShyMT8iInJdDDcuakCUnzQcZSswzi6txaiXN+N/f6bL2DIiIqK2xXDjonw93DEkJgCCAIzpGeLw2Nrj+SjQ1uHtjWdQUWto5hmIiIguT25yN4DazqdzhqK0So/YYG9EB3oiu7QWAJBTXos31idj+f5zKKvW47/T+8ncUiIiIudhz40L03i4S6sVf3vvCPxw/wgIgmUxv82nCwEAa47nw8wNNYmIyIUw3HQS0YFeGN4tCDGBXgCA4io9AMvaNweyyuRsGhERkVMx3HQyvcJ9Gx1bfSxPhpYQERG1DVnDzcKFCyEIgsNXQkJCs+cvW7as0fkeHh7t2OLLX0K4Rvo+XGO5d6uO5qFGb7yk5xVFET/sy8KR7PJLeh4iIqJLJXvPTd++fZGXlyd97dix47znazQah/MzMzPbqaWuoXdEfc/NA2O7oYu/J4oqdXh7Y8olPe/p/Er86+djeOqno5faRCIioksi+2wpNzc3hIeHt/h8QRAu6nxy1Muu52Z4XBBig7xx17J9+HRHBm4aFNXksFVLlFhreIqruMUDERHJS/aem5SUFERGRqJbt26YNWsWsrKyznt+VVUVYmJiEB0djenTp+PEiRPnPV+n00Gr1Tp8dWYxgV4YGR+EEd0C0SvcF+MTQjGuVwhMZhEbTxW0+nltw1pVuksb3iIiIrpUsoab4cOHY9myZVi7di2WLFmCjIwMjB49GpWVlU2e36tXL3z22WdYuXIlvv76a5jNZowcORLnzp1r9jUWL14MPz8/6Ss6Orqt3s5lQaEQ8O19I/D9/UlQKixLGA+ybrKZUVzd6uetNZgAADqjGUaT+dIbSkRE1EqC2IE2GiovL0dMTAzefPNN3HPPPRc832AwoHfv3pg5cyaef/75Js/R6XTQ6eqHSrRaLaKjo1FRUQGNRtPkNZ3NqqO5mP/tIQzq6o9f5o5q1XN8vzcLT/9yDABw5Lmr4efp7swmEhFRJ6fVauHn59eiz2/Za27s+fv7o2fPnkhNTW3R+e7u7hg4cOB5z1er1VCr1c5qokuy7Rp+KT03NXqT9H21zshwQ0REspG95sZeVVUV0tLSEBER0aLzTSYTjh071uLzqWm2cFNWY0BZtb5Vz2EblgJwydPKiYiILoWs4eaJJ57Atm3bcPbsWezcuRM33HADlEolZs6cCQC48847sWDBAun8RYsWYf369UhPT8fBgwdx++23IzMzE/fee69cb8EleKncEOlnWfMmvbiqVc9Ra9dzU6UznedMIiKitiXrsNS5c+cwc+ZMlJSUICQkBFdeeSV2796NkBDLLtZZWVlQKOrzV1lZGe677z7k5+cjICAAgwcPxs6dO9GnTx+53oLLiAvxRm5FHdKLqjE4JvCir7cflqrhjCkiIpKRrOHm+++/P+/jW7dudfj5rbfewltvvdWGLeq8ugX74K/UEqS3su6m1lAfaDgdnIiI5NSham5IPt1CLHU36UWXPixVzZobakPHzlXg6LlyuZtBRB0Yww0BqC8qTitqXc+N42wp1txQ2zCYzJj58W7MXLobeiPXUyKipjHcEACgT4RlzYC0oqpWDSvZz5aq5rAUtZE6gwlVOiOq9SaH3kIiInsMNwQACNV4INLPA6IIhy7/Kp0Rz608jmPnKs57fcN1bojagtFUv+aonithE1EzGG5IMtC6DcPh7HLp2De7M/HFrky8tfHMea91rLnhv6ipbRjM9YHGaGa4IaKmMdyQ5IpofwDAoaxy6djBrDIAwNkLzKLisBS1B/ueG4Oxw+wcQ0QdDMMNSa7o6g/A0nNTXKWDwWSWgk52WQ1M5uY/TOxXJWbPDbUVDksRUUt0qL2lSF79Iv0AAEWVOgx5YSOGxQWisNKy6ajBJCKvohZRAV5NXlvLmhtqBxyWIqKWYM8NSTxVSiRah6YAYG9GqcPjWaU1zV5rPyzFRfyorXBYiohaguGGHLxyU388PTUBY3uGNHosq6TpcGMwmWGw+9DhxpnUVgx2Q1EcliKi5nBYihwkhGuQEK5BUrcgbDtTBADw93JHeY0Bmc303NQ0qLHhIn7UVox2dV8GhhsiagZ7bqhJidH+mDYgAsE+Ktw6tCuA5ntu6gyOYYbDUtRWjHaBxn6IiojIHntuqFnvzxwIANhwsgBA8zU3DXtuuCs4tRX74U/23BBRc9hzQ80SBAGCICAmyLLvVGZJ02vd2GpslAoBgGUquPk808aJWst+hhRrboioOQw3dEHRgZ4AAG2dEWXV+kaP24algrxV0rEaA+tuyPlYc0NELcFwQxfkpXJDbJBlfZudaSWNHrcNSwV6q2DtvOHQFLUJ+zob1twQUXMYbqhFJvcLBwCsPp6HQ1llDvtP2cKNl0oJb5WljItFxdQWjJwKTkQtwHBDLTKtfwQAS3HxDR/uxK1Ld6Gi1gCgfljKU6WEt9oSbhoWGRM5g4HDUkTUAgw31CL9u/ghKsATeqPlA6XOYMbBTMummrYg4+nuBi+1EgB7bqhtcCo4EbUEww21iCAIuGZApMOxvWdLsfTPNPywLxuAZVjKx9pzw/2lqC0YORWciFqA69xQi82/qjvCNGrU6E14bV0yvt6dicq6+hDj6a6UZkwVaHVyNZNcmIFTwYmoBdhzQy3mo3bDXaPi8Ddr/Y19sAEsNTcXWhOH6FJw40wiagmGG7posUFeCPZRNTrupVJKU8YzilsebrR1BuxKK4Eo8sOKzs9+KMp+QT8iInsMN3TRBEHA0NhAAEAXf0/puMpNgZhgW89N01s1NOWVNacx8+Pd+M+K485tKLkc+0X8OCxFRM1huKFWmTe+Oyb3DcOyu4ZKx1IKqxBnG5YqrW7xFgwrD+cCAL7dk4XtKUXObyy5DPvZUhyWIqLmMNxQq/Tr4of/3TEEPcJ8MalPGADghiu6oEuAJ5QKAXUGMwoq61r0XEF2Q1zPrTzB4SlqFjfOJKKW4GwpumTvzRyIrNIa9Aj1gSAIiArwRGZJDf6+ZBfMoojVD49GgHfjGh2bosr6mVXpxdVIL65GfIhPezSdLjP2dTasuSGi5rDnhi6Zh7sSPcN8IQiWjaVsM6ZyymuRV1GHv9KKG12z9ngehr+0ERtPFkiLAA6OCQAAbD5V2E4tp8uNQ80Nh6WIqBkMN+R0thlTNnnljYenfjuSiwKtDl/tzgQAeKuU0hYPm08z3FDTuIgfEbUEww05XWCDIaizJdUo1NbhrN308LRCy/e2LRxCNR6Y0DsUALDvbCm0dYY2aVuNnisnX84cCooZboioGQw35HRjeoY4/Hy2pBq3LN2NKe/8iaySGhhNZmkdnErrNg0hvmrEBHmjW4g3jGYRO1MbD2VdqvUn8tHvuXX4Zk9mq64XRRGphVUtngVGzue4cSb/HIioaQw35HSDugZg1T+uxGdzhgAADmSWIaO4GnUGM77Zk4lzZbWN1igJ9VUDAEZ3DwYA7EoruajXrKg1YPzrW7HwtxPNnnMgqwxmEdh/tuyintvm54M5mPjmNizZltaq6+nSseeGiFqC4YbaRL8ufujXxQ+AZQdxm+X7s3EyT9vo/FBfDwDAiG5BAIDd6aUALCsdX/XGVvx84Nx5X+9Idjkyiqvxx7G8Zs/R1lqGuspr9BfxTuqdtrY7rbCqVdfTpWPNDRG1BMMNtZkQHzW8VEqHY2U1Bry7KaXxudaem+HWcJNcUImSKh1+O5yL9KLqCw4lFWgtRcvlNfpm18mpsIWb2tbV85TVWK6r5I7nsrEfljJyWIqImsFwQ21GEARpWjgA9OuiAQCczq9sdK5tWCrQW4WEcF8AwJ6MUpwpsJybnF953lqXQutaOQaTKE0tb0gKNzUtDzeVdQa8tu40TudrpR6fyjYqdqYLsx+W4vYLRNQchhtqUzGB9dPCX70pET7q+nUj7TffDNWope/rh6ZKpHBTrTchp7y22dcp1NZPNy9rZtipohXDUn8czcMHW9Lw9oYU6Xmr2HMjG65QTEQtwXBDbSom2BJuQn3V6B3hi9tHxEiPjesVKn1vq7kB6sPN1uQih93Fm+rxsSm0W+W4uZ4ZW7ipqDW0eMZTgdbyvHnaOmlYqqqO4UYu9qsSM9wQUXMYbqhNJUb5AwCu7B4MQRBwz5VxcFMICPRWYVyv+injtmEpABjZPQhKhYCs0hqHFWmT8xsXItsUtKTnxhpOzCJQ2cKAYnuu4kqd9H1Lr5XD2uP5mPvNgTZbJ0hu9nU2rLkhouZwbylqU1P7heOLu4fhimh/AJbC4a1PjgMA1FprY1RuCvh7uUvXaDzcMairP/Y1mLJ9yq7nxmwWkV1Wg66BXhAEQephAZruuTGbRYdC4PJaPfzsXrM5tkBTVKmDwdpr0JELij/eno4DmWW4dkAkplpXfHYlBtbcEFELMNxQmxIEAWMbLOoXFWAZqhJFEfdcGYfoAE9pXyqbsT1DpHDTxd8TOeW1SLaGm+IqHeZ9cxB7Mkrx6t8HYMbgKIfNN5uqqamsM8J+ElV5jQExQRduf2m15bnsP0j1RjN0RhPUbsrmLpONbcisI/cuXQqjmTU3RHRhHJYi2QiCgGeu6YM5o+IaPTa2Z309zjWJlh6IjOJqVOuMuPl/u7Anw7IOzqGscpTXGBzCR1kTPTcVDaZ/Nzd01VBz9Tsdte6mxmBpl6sWPRu5QjERtQDDDXVIfSM1CPax1OFc1SsUQd4qmMwilmxNQ3pRfZFxfkWtQzExUB9ccsprccC6d1V5rWOYaRh27NkXG9t6bhqyhYelf6bhtyO5LX1bba5GZxnqq3bVcMMViomoBRhuqENSKAS8f9tAPHNNHwyLC8SkPmEAgI+sWx+EWaeO55bXORQTA/WFw/O+OYi/f7QTJ3IrGoWZ5npkXl17GoNe2IDMEkuAaq6Hp7LOiLPF1Xhp9Wk89dORDrPflG2NnyoX3SCUKxQTUUsw3FCHNaJbEO65Mg6CIOBv1uJY27DE7JGxAIDc8qZ7bgwmM47nVEAUgb9Si887LGUyiyiu0kEURXy4NQ3lNQZ8uycLdQZTswsCVtYZpWnqdQYz8hsELDmYzCJqDa7dc2NwmAreMQIlEXU8DDd0WUiKD5JmVKndFLhlSDQAy8ylVOteTxoPS318WY0B58pqpSC0/2zZeXtu3tpwBkNf3Ijl+7OlY54q5XlXMq7SGaXeHQDIKq25lLfnFLZgAwDVuqZD2eXOvufGZBY7TI8ZEXUsDDd0WXBXKjC5TzgAYHSPYAT5qBFgDTuHsix1Nb2s2zaU1+iRUVy/ueWBzMbhxv7njacKIIrA4jWnpWNVdcZm620AyxYMmXaBpiOEmxq7oSiXLShuMBRl35NDRGTDqeB02Xh0Ug+YRBEPjOkGAIj090RZjQFHz1UAsISbfWfLUF5rQEZxfdgoqdbjaLblHF8PN1TWGaVhqTqDCSnWnh/7npriKt15Z1RV6YzItg83JR0g3Ojse25cM9wYGvTUGEwi1Py/GBE1IGvPzcKFCyEIgsNXQkLCea/58ccfkZCQAA8PD/Tv3x+rV69up9aS3CL8PPH6jET0CLP00ET6ewKoH44ZZ50+XlFrkIaqbDYnFwIAYoIsa+zYgsypPC1MTQxtFFfpzxtuKuuMyCzpaD03rh9uGvXcGNlzQ0SNyT4s1bdvX+Tl5UlfO3bsaPbcnTt3YubMmbjnnntw6NAhXH/99bj++utx/PjxdmwxdRRdrOEGsPTIXNkjGAAgisCR7HIA9ds66K0fgjGBll3KbcNSx3Ob3tKhuEqHMuuwVIRf/b5Xtunp2jqDQ6DJ7BDhpjMMSzXoueGwFBE1QfZw4+bmhvDwcOkrODi42XPfeecdTJkyBU8++SR69+6N559/HoMGDcL777/fji2mjiLS33GzTQ93pbTr+Mk8S2iZNTzG4Zr6nhtLcDmRYxmuigv2djivuEqH0mpLALL1FAFAdKAlUKUVVkNn12uQ3QHCTbXe9QuKG4YZOWZMbUkuxJbThe3+ukTUcrKHm5SUFERGRqJbt26YNWsWsrKymj13165dmDhxosOxyZMnY9euXc1eo9PpoNVqHb7INUTa9dyMjLfspeDfYL+oWSO6OvS82MJNRa0BJrOI47mWcPPoxB6YMTgKj0/qCcCyeF9JtWWKeY9QH+n6roGW609arwv2UUnnV8q8WWWtXc+N6w5LNei5aedhqTqDCQ98dQAPfHUAdQbXDJBErkDWcDN8+HAsW7YMa9euxZIlS5CRkYHRo0ejsrKyyfPz8/MRFhbmcCwsLAz5+fnNvsbixYvh5+cnfUVHRzv1PZB87MPNqO6WHj/HDTjdEOyjxo2DukjHYoO84aN2g1kEfj5wTtqvalDXALw2IxEPjYuHIFh2Dk8rstTtRPh5ICbICyqlAgnhGgBAboVlXZuEcA2CvC0BR+66G/vemiq9EaLoWtOkRVF02H4BaP+F/LR1BuiNZuhN5vMuFUBE8pI13EydOhUzZszAgAEDMHnyZKxevRrl5eVYvny5015jwYIFqKiokL6ys7MvfBFdFrqH+iDAyx0J4b5S78o1AyKlx/tG+gEA/j64PtAGeqtwv3W21VM/H4XBJCJc44GoAEtQclMqEOBlCStnCizhxt9Lhe/uG4Hf/jFKGpay6RrkhWhrb05rZ0ydKajEG+uTL7nnp8auJ0EU0ewChJcr+2CjcrP8r6u9h6UcAqSO4Yaoo+pQkyj9/f3Rs2dPpKamNvl4eHg4CgoKHI4VFBQgPDy82edUq9VQq9VObSd1DBoPd2x+fByUSkHaVfzBsfG4LjES284UIambZagqLtgbj0zogbyKWnQP9cF9o7vh2z1ZyNfWQe2mwLszBzrsSh7so0JptV7aaTzQ2x2R/p6IhCcKtI6rIfcK84XJJOJwdjn+TCnGVOtKyhfjtXXJ2HCyAKEaD9wxIubCFzSjpsFQVLXOCG8XmidtP6vNS6WE3mhu954b+w1TXXXndSJXIHvNjb2qqiqkpaUhIqLpD4ikpCRs2rTJ4diGDRuQlJTUHs2jDijAWwWNh2OdTaS/J2YO64pYuyLhxyb1xKt/T4QgCPBUKbH4xv7oHaHB/+4YjGFxgQ7X22ZE2YRp6mt2fBqEhQm9Q3GDddjrt8M5Tda6pBdVSbO1mnLSOmMry27F49aobtBT42ozpuyDjJe7stGx9mB/TxluiDouWcPNE088gW3btuHs2bPYuXMnbrjhBiiVSsycORMAcOedd2LBggXS+Y888gjWrl2LN954A6dPn8bChQuxf/9+zJ8/X663QJep8QmhWPPIaIzrFdroMftwE+yjQm9rnQ1gmXJu0zdSg6gALwyPC0RskBeq9Sb8cSzP4bm2pxThqje24YU/TgKwTNe2r4WprDMgp7wWAKT/tlatvmHPTdsOSxlNZsxcuhsLfjnWpq9T/3r1981DZQk3ehnDjauFRyJXImu4OXfuHGbOnIlevXrh5ptvRlBQEHbv3o2QkBAAQFZWFvLy6j8sRo4ciW+//RZLly5FYmIifvrpJ6xYsQL9+vWT6y2QC7IPN+N7hUKhqB+ysg83k/tahkMFQcAtQ7sCAH7c71jTtTOtBACw4lAOVh7OQZ9n1+HrPfUzAs8U1BfP55RdWrhp756btKJq7EovwQ/7sppcCNHZbNPABQHwcLOEm4azp9qafc9cFXtuiDosWQfkv//++/M+vnXr1kbHZsyYgRkzZrRRi4iAYF+V9P2E3o6z83zthsCuSqjv9bnuiki8svY0DmaVo7LOIJ2XZl0pWVtnxP+tsCw2+evBc1Jtzel8u3DTyp6b5fuy8e7mFAR6qxyOt/V08ALrTuhm0bLLesPhPGezBRl3hQLuUkFx+/bcVNrdU63MU/+JqHmuU21I5CQ6Q/0H5ugejotK+qjd8OTkXtAbzegbWT9c1cXfEzFBXsgsqcH+s2UYbw0+tunkQH2NxtFzFajRG+GlcsMZu3BTXKVHncEED3clRFF0KHJujtks4qmfjwIAzjXo+anWt224KaysL64urtK1W7hRKgS4W3vT2jvcVHNYiuiy0KEKiok6gmsTI6BUCLhmQESTs43mje+Oxyb1bBQ+bLOzdqVbhqIMJrPD/lM2RrOIA5mWnczte24AS0A5U1CJxP+ux/OrTjo8ll5UhTs+3YPD1q0lAGDf2dJm38e25CJ8ueusU9a7MZrMjRats/XcAEBJVfP7cDmLbVjKTSnAXWn5X5f+Mh6WMpjMuGnJTjzx45FLbZbsGu75RSQ3hhuiBrqH+mLffybizZuvuKjrRtjCjbXOJqu0BkazCA93BdyVliBkWyF5T3opRFFEsrXmRmX9sM4pr8VHW9OgrTPimz2ZDh+mS7amYXtKMT7bkSEdW3kkt1E7vK3Ftr8cysGzK0/gYFbZRb2Ppsz8eDeufGWLQ29FUYOem7YmDUsp64el2vtDtdKJU8EzS6pxILMMvxw81y41S23l4z/T0X/hehxywu8ZkbMw3BA1IdBbJS0U11K2cHMit8JhZ/Ieob544+Yr8PTUBDw0Nh4AsDu9BFmlNSivMUAhAEPjAgBYNvz8/aglsNQZzNhs3cPIbBax9UwRgPqhrtJqPVY3mJ0FAKF2U9cBNNoh/XyKKnX4K7XYobenzmDCvrNlKK7S4XRe/fYlhZV1Dte1NdsQlJtCgEp5+Q9L2VY4Nov1e51djv5MKUKtwST1RhJ1BAw3RE4S7ueBuGBvmEXgnY0pUqiID/HGdYmReHBsPJKse2AdOVeOtzacAQCMjA9Gt2DLCstvbjjjsOruH0ct4eVknlYKEOlF1SjQ1uHm/+1qcguAkAa1L00NjTXniR+PYNYne/DWxhTpmH0tT3px/Vo89gsaFrfDsJRthWJ3pQJuCnmGpRzWuXFSuAEsQfVyZfuzr6hlgTV1HAw3RE40f3x3AMBnf2XgtXXJAID4EMeNN4fFBsJgErHisKWHZvbIWHQJcNzW4aFxlh6eLcmFqKg1YGty/S7UtQYTnv75KFILqxCu8cBv80c5XBuiaTrcZJfWYMEvRx2mn9szmszYZu0dendTCnakFAMAzpXVh6MMu3Bj33NT0i7DUnY1NzINSzku4ndpH+bldmGgPcJhW7H92WsZbqgDYbghcqKbBkfhxRsc112Kt9tVXBAE/Hd6Xyits32iAz1xVUIouthtAjq6RzCevLoXuof6QGc0Y943B/Fbg9qaLcmWEPL89f0wIMrfYcPQhj03Z0uqYTaLePSHw/hubzZe/ONUk21PaTB89fZGS89Stl3PzdniauxMLcZfqcUo1DrW3Dh7o87yGr1DmLL1aLkpBKmGSc4Vii+1oNh+KMq2A/3lxmwWpV4n9txQR8JwQ+Rks4bH4If7R6BbiGUH8sExAQ6P947QSJt3Pjg2HkqFgF7hvtLjr89IhEIh4M2bE+GlUmJHajHOFFTB012JxGh/6TxBgLR1RIRffTjyVisdXi+zpAbf7cuSaiK2pxQ1WSNz9Fw5AEi7nCfnV0IURYeem8PZ5Zj9+V7M+mQPdHZbSpwpqMLIlzfj7mX7Gs2qaq17v9iPq9/ahrPF1TiVp8X2FEugc1cqpALs9t8403k1N/ZhoD1mm7WFilqDNFzIcEMdCde5IWoDw7sFYeNjY6EzmuGpUjZ6/KnJvTBreFdEBVhmT/UM88Wyu4YiNshb2stqQJQ/Ppw1CE/+dBT9u/jh4Qk9sP5EPo5Yp4L3DtfAz9PSYxPoXd9zo7Sboi4Ilg/h//xqWUDQw12BOoMZX+w8i4Fd/TG2ZwjcrEHhcHYFAGD6FV2wbGcGKnVGFFXqHGpu8irqh6Ls2RYgzKuow8PfHcL7tw266IJse7nltdhvDWOHssvw0urTUiBzUwrwsO4t1VRIK9TWYfbn+3DToC64d3S3VrehKc7cONO+5qbkMq25se9xYrhpPaPJLP09JOfg3SRqIwqF0GSwASzDU7ZgYzOuV6jDZp+2Y/v+MxGfzRmKK6L90d1uiMt+w09/r/rVie8cGYshMQF4/vp+iLCbORXiq8a/piQAAN7fkop7vtiPz/86Kz1uC03D4gLQNdDSttSiqkaLA9pruJEoAKw/WYAbl/yFCW9sxfCXNiKv4uJXXrb10gDAjpQShxCjVCgwopvlvW8+XdhoOGzV0TycytPik+0ZcLaGe0uZL2EKd7lDz03rh6WS8yvx+rrkNl8xeU96CUa9vBlrj+dLx+xrhRhuWueT7ZxK3xYYboguI/bFybYPeADw96zvuQn2UeOnh0bijhExiAmqD0vXDIjA9Cu6wNO9PnDtSLUUDdfqTdKaO4nR/tLrpBVW4VypZVjKTdF4xWT74TQAuHVoNPw83XE8R4u0omoUaHX4fq/jflt70kuw/zyLDwLAn2eKpe83nMx3eMxdIWBMzxCo3RTIKq1ptBDiAeuHRL62rlXBqjmiKDYaiqq6hFWgHWpuLmFY6o31yXh/Syp+b2LNI2dacTgXOeW1WH/CPtzUhzIt99pqle0pxag1mM67ICddPIYbostIfKgPVG6WRQGHxtaHmwAvVZPnh9rNnLouMRKB3ir8Om8kFl7bBwBwKKsMZrOIvWdLYTKLCPVVI1zjIfUQHcupkIZMBnb1B2AZ2rKp0Ztgv1DzY5N6YvUjo3Hr0GhMvyISAPDTgXMwm0WYzSLeWJ+MW5buxm0f72l2bRyTWZRCF9D4Q9NNKcBL5YbRPSwb7M7/9iDGvrYFJ3Mta/ActFtv5VBWeZOvcfRcOe79Yj9O52ubfLwpdQYzGnbUtKao+FxZDbJLaxxrbi6hoDjVuu5RXnnTQ4bOciLXMmxZXN10KGPPTevYQm5ZE8s6UOsx3BBdRnzUbvhs9lB8NmcoguxmRdnWz2nIS1U/bHSFtRg5IVyDWSNi4OGugLbOiPTiKiy37mY+pV84BEGQem5sPSi+Hm5IjLJcPzyu/rV8PdxgPyoUpvFAF39PvHzTALxy0wBoPNyQU16L34/m4qFvDuC9zakAAL3JjLXHGy9ACFiKlitqDdKMqIZsWy9M7mvZ1DStqBqZJTX4eHs6cstrHeqCmuvqf2XtaWw8VYApb2+H3tj0jKvCyjocz6mQfq7UWT58BAHS7LQqnRE7U4tx/5f7W7SQoc5owrXv7cC17+9w3L6ilTU3RpMZ2daeNfup+a2lN5odCshtDCYzTudZesjsh9Dsv9cbG2/RQRdmG568nBdy7IgYboguM1f2CJZ6LWxGdQ/GB7cNwtpHRzsc/8dV3TGoqz+WzBrksBeWu1KBAdawsulUITacKAAA3DwkGgAQH2oZzsq3fgBHBXjh1mFdMSwuEP+4qjt+mTsSI7oF4qUb+ts9p2MY8XBXYvoVXQAAj3x/GOtOFEClVGBsT0vbVx7OxQdbUrHycI7DdbZVl6/uG95kUbJteGxSnzD4e7lLRdVrj+c71OoAzffcnCmon/b+0ba0Ro8bTWbc+r/duPb9HdJwQbXO8sHtrXKDxrrre2WdAe9tTsX6kwX4Zk9mk69lL7OkBmU1BpTXGBwWQWztsFRueZ00Y8wZq0Q/+dMRXPnKFmnmnE1KQRX01mn39m0tatBu9t5cPFtheVk1750zMdwQuYhpAyKQEK5xOBbp74lf5o7C1P4Rjc4f1NUyRX3xmtPQm8zo10WDfl38ADjW9gBA91AfdA/1wfIHkjAkNhCDugbg+/uT0D3URxquampm0n2ju2FgV394uCsQE+SF7+4fgcU3WgLR/swyvLYuGY8vP4JqnREmswiTWcQq6/YT11/RBd0aFFgDkGaV+HupsP2p8djz7wmIDfJCrcGEtzZYVlYeYw1Qx3IqpJ6ZokodnllxHGcKKh1WBF6yNQ21esceh5WHc5FeXA1RtDwO1A9B+ajdpEJqbZ0Rp6xDW80FKXtpzWyFUVFraLYH6XwySurXASpywkKK+89aerps+6PZHM+t78Eqqa5f06hhIbS21oCKGgPu+HQPfjl47pLb4+pMZlEqBC9jz41TcSo4USdlCyU2s4bHSN/7e6ng6+GGyjoj1G4K/HNSz2afZ8mswdh2phA3DIxq9FjXIC/8OncUzGYRggCp92hITIA01dtoDTSvrTsDfy93FGh10Hi4YUzPYKw4lIPT+ZVQuSmkD3/7Ohdfaw/K9QO74O2NKVJP081DonD0XDnKaww4kVuBgV0DsPTPNHy1OxPbzhTBZBbh7+UOb5Vl2GxHajEm9bEMc+mNZnywJVV6jc2nC5GcXykVE3urlfDxsPyvM62wSvqXt61+SdFE4bWNbV8wewrBsr9UWY1eWgagpc7arxitdQwab288gx0pxXj/tkEI97vw89YZTNKU/uQGRdon7IbnDCYR2loj/LzcGw2nVdQacDCrDNtTilFSpceNgxr/TlC9yjqDNKzb1FYq1HrsuSHqpIbFBsJLpYSXSokFUxNwi3VIyuaZaX1wXWIktj81HnFN9KDYhPt54JahXc+7ro1CITgMi82/qjv6RGgQ7GMphH7hj1MortJJ+3FN7RcBtZsS8SGW1+0ZVt+T1NQMqBlDouHv5Y5gHzUemdADk/uGY5i14HqntRfCFqayrDUqvcM1UqCxzchadyIf417bgvTiavh7uWN8L0sP0LKdGdICfj4e7tBYw439DBdL/VJ92GhKWpHj4z5qNwR6W2qnLmZoKrWwCk//fNSh8LqkWi/tLm4yi3h7Ywr2Z5Zh1ie7W7RNhf0eZKcahJvjuY6F18XWAmjbbCnbH21FrQGnrLU59jVFHUlOeW2TdUVysA807LlxLvbcEHVSAd4qbH58HNRuCgR4N55tdfPQaNw8NLqJKy/duF6hGNcrFL8dycXD3x2SFsTTeLihUmeUXndk92C8tyUVY3uG4HiO5QM2t4lZQV38PbH33xOhVAjS1haje4Zg/ckC/HmmCPeOjsOJHMcP6N4RGkzsHYplO89i46lC/HmmCPO+OQijWUSIrxov3dAfbkoBW5KLsDu9VCqk9lErpWGpvRmO03cPZpU5rEVkMJmx4lAOtqcUI9Bb1WhfLz9Pd/h6uKG4Soe9GSXoGuTV5NpBDT278rgU2mxMZhFlNXoE+6gdXietqBrvb0nFoxOb730DgIzi+l6ltMIqGExmuCsVKKvW45i158bWg1ZSpUd8SH0gi/TzRE55LSpqDdKstZJqPfRG8yUt5uhstoLuiloDVswdhf5RfrK2x36to/IaA0RRdPhHALUeww1RJ9aS4Yq2NNJulpeXSont/7oKNXqjtJ3EiG5BOPzs1dB4uOGDLZbaF30zvRANP0RHdw8GYAkcezNKG13XO8IXQ+MC4efpjtJqPWZ/vheiaFkP6PUZifBwV0ozWDKKq6V/7dv3ttim73qrlKjWm3Aoq0wqyjaYzPjHt4ew9oTjOj32/L3cpZlXC38/iS92ZWL5A0kI8VU3ew0AaSuNhgq1OgT7qBvV//xvWzpuHxGDYJ/mnzejuL43Q28y42xxNXqE+eLbvVnQG83oG6mBh7sSBzLLUFKlQ53BJA3VdQvxlsLNqbz6EFlYWYc6gxnRgZ5QuzW9oGV7yi6tleqtHvhqP377x5XnvSdtzX6GlN5kRo3eBO8WhFu6sI4TqYmo0wn2UaN3hKUIemq/CPh5ujvskwVYejcEQcDfB1vqN6b0DW/Rc8cEeSEqwBMGkyjNiPKzW+ywd4QG7koFrku0rMcjisDYniF44+ZEaXsHfy8VulmHxrZbd0n3VrthxpAoh/V9rrPOCvvtcC6W/pkGURTx7MoTWHsiHyqlAoPs6pvsr/P3csfA6Pq9xzKKq3HXsr0Oe1g1ZDSZ0XCP0kBrz5utqPhwtiX8zB0Xj8QoP9QaTFJhdHPse24Ay9CUwWTGl7vOAgDuHhUnDSOmFVXh4e8OAbCEyijrrvYncrWotGv7j/vPYeKb27B49WlsTS5E/L9X4+cD7VNobDaLjYbjskrrhwVzK+rw6Q7nrmJ9rqwGq47mtngT2Yazy9pyaOpIdjmmvrMdW5ML2+w1OhKGGyKS1YNju6F3hAYPjTv/PlDPT++H92YOxKszBrToeQVBwOgelt6bv1ItQzhzRsYi0s8DkX4e6GGt43nmmj74ff6V2Pn0VVh219BGPQy28LHHOgQV5e+J3hEah5A1d1w8BnX1R7XehJdWn8aa4/nSbKH3bxuIxTfWtzk2yFsKWf6eKjw2qSe2PzUeG/85BkHeKhzP0eLdTSmN3o/eaMaGkwU4katt1AvVN9ISEAutdS62nptBXQPw+NW9AABf7c6UCppFUUR2aY3Dh/BZa8+NrZ4oOV+LNcfzUaDVIcRXjWsSI6S1lV5ffwbrTxbATSHg0Yk94OdpCT0NZ1nZpvn/cSwP3+3Ngsks4scDjitWO4PZLOK7vfWbw4qiiAe+PoA+z67D/G8PSrvL29cVAcCmUwVObceCX45h/reHsO1M0YVPRuMi4qaKilsalC7kj2OWbUl+aqdwKTeGGyKS1fQrumDNI6PRPdT3vOd5qpS4NjFSWmOmJW4cFAX7yUsj44Ow+pHRWPPIGCnEqNwU6B/lh0h/zybrHexnlSkES/EyAPz7b73hq3ZDrzBfRAV44qcHR+Im6+ygdzelQGc0I8hbhUl9wtAr3BcDomzT7L2lPcT8vNyhVAiIDvRC91BfvGYNbp/uyEBqYX3djNks4uHvDuG+L/fjoa8PALAsyvjZnCH4Ze5IhPpahheLqnTQ1hmkVYuv6OqP0T2CMbpHMPRGyzCZzmjCWxtTMPrVLQ4fdLZi6El9LKHtWI4W31rX7rltWFeo3ZQIblCb9cbNiZg7rrsU1myzrWzOWsNEUaUOm09begwOZ5e3aNq72SzC0IJCaMCyCvaCX47h/i/3w2AyY0dqMTacLIDeZMaqo3lYvPoUgPpwc+vQaCgVAs4UVEmLIDrDCWu90bFzFRc406JhmCltMPvsYFYZej2ztsm1mC5WrvXPJuMCRe8XS1tnwI6UYqeFMGdhuCEilzU0NhC/zb8SU/qGY9qACAyKCYC/lwp+Xi0PSPbhZkq/cERbNxWNDvTC5ifG4aeHkiAIAhQKAVP7WYKBbb+robGBUmB6aGw8BAG4KiEMcUGW57DfEwywPDaxdyiMZhH3f3kA3+zJxLxvDuLWj3dLtTu51hWYe0f44qqEMAzqGiDV6BRV6vDdniyIIhAd6IlgHzUEQcDrMxIR6K3CyTwt/rn8iPRh+ctBS89KZZ1Bmvk0c5glvP15xlJIrRCAW6wF3kEN6lNGWeua/Bq8D/stOmxsiw3WGcw4llOOI9nlMJjM+Gp3Jv72znb8b1uaNBxnMouYs2wfhrywEcn5lTCZReiMTa9+XKUz4tV1yQAsRcx/ninC69afE62rcttWmrbNlOsf5YfB1nWetjhpmKasWi+Fk2S7gu6M4mqsPZ7X5GrZ5bWOYWbRqpMY9fJmKYB8vSsTeqPZKWsG2VbuPltc7dQg8tIfp3D7p3vwWxvvbXaxWLlERC6tXxc/fHTH4FZf3yvMFxoPN2jrjLh7VJzDYw0Lf4d3C4RSIUhTsofa7dw+tX8ETi2aAg93yxT33PI6TBvQeHHFhdf1xfEcLdKLq/GfX487PGYrXLa1q2E7fj+SJ4WU2+3WLQrTeOCNmxNx97J9+ONo/bYX+86WQltnwK/WkBPkrcKQ2EDcPCQKy/dbPlDH9QpFpL+lpibIp77nJi7YWyrG1XjWf5QoBGBa/0j8fJ4P5Ae+OoDiKj26BnpJgeNknhY7Uovx1T3D8eGWVPxpHdqZ9+1BGE1mlFTrcWdSDNadKIDGww3f3jcCHu5KvLspxWEDz2dWHEduRR083ZV4+5YrMP71rcitqENZtR6Z1kUPY4O8MT4hFHvPlmLz6ULcmRTbbFsbKq3WQxRFh6AniiLS7WqWUqwrYG9JLsRdn+8DYFlZe/u/xjvUlFU06LmxLYXw5a6zWDC1NzZah83OFFShotYghUhRFFGtN7VoZp1NnrXnplpvQlGlDqEXuaZSc3alW4Yi/zxTLK1I3hGw54aI6DzclAp8NmcoPrp9EIbYbVbaFF8PdyTaTS8eHud4vq1QeXi3ICx/MAl9IxtPRY4K8MLqR0ZjWv8IxAZ5Yf747nh+el8sfyAJ99itAt3LbjXqUGu4sX3Izx/fHfePcaxhGt8rFP/5W2/pZ42HG4xmEf/+5RgW/n4CAKQP+aemJMDXWnszc1hX6Rr7mUWDYwLsnqu+5+be0d2kWqeGYq09VsXWKeS2YHNtYiQUgqVoe9OpArxtrTnydFcitbAKZ0tqUFlnxAdb0pBaWIWDWeX4fm8W/jxThI+3pwMAHr6qO4D6nq1HJvZAXLA3ulp72o7nViC7zPIB3zXQCxN6hwIAdqaWtHhfJ53RhGnvbseUd7ZLM8U+2Z6OhGfWNhjis0ylX3WkPkgazSIOZpY7PJ9tKrhK6fhR/PuRXPyVWuywaezh7Pprv9yViX7PrcOKQ45blzQltbAKNXojCuy257jQekwtpa0zSEN9B5vZx00u7LkhIrqAC4Uae6O6B+NgVjl81G7STLCLFeitwgezBjU6HqZR491NKVAqBCSE+9odr/9X+MNXdcdjk3o2WT90z5VxcFcqoFAIyCqpxsfbM7DK2pMzOykGD0+wBIRgHzW+umc4zhRUYqI1BFiO1/fcDLELN91DfeCmEBCm8cA/J/V0mIreM8wHxVV6lNfo8ejEnnj0h8MALIEm2EeFCD8P3De6Gwq0ddibUYp/Lj8Ck1nEpD5huGNEDB7+/hBG9wjBFdH+WL4vGxH+HtiaXIR3NqVAhGWW223Du+KxST2x6lge0ouqcc2ACDxgDXd9IzXIKq3B5tOF0BvNcFcKiPT3hEKwzJg7lafFb0dyHXpvjp2rQNdAr0bDl6fzKqXhndXH8nDzkGj8eigHOqMZ3+2tL5Q2mERkFFdLhcXdgr2RXlyNo+fKHXrrbLOjugZ5Sb02gCX8Pb/qpMNrH8wsw9ieIRBFEZ/ssAS6tzaeQZXOiK93Z+JfUxMwvleowzUrDuXg0R8O4+o+YVJvImAZKhvRrX4ZBm2dAQ99fQD9uvjh6SkJLV5r56Td4o4ZxdUoqdI1GrqUC8MNEZETTRsQgf/9mY5rEyOkBQWdJSbIGx9aQ4/9wouDuvpj5rBo9InQ4I7zDLEIgoDZIy2P70wrxsfbLVOhbx0ajeeu7evwoXZFtL+0k7xNkHf9B9fArvXhJtLfE1ufHIcALxU83JUO6yf1CPPF27d0R3mtHkNiAvHmhjMwmMz473V9pSnsADC5bzj2ZpRK06MfGNMNQ2IDceiZSVK77rkyDnqjGRPe3IrsUksvTGKUH569pg8EQcA7twzEjtRizBkZK13TJ0KDNcfzseaYpWYpKsBL+nOZMTgKi1adxPL92VK4+WhbGl5ecxpje4bgi7uHObx/+w1Ffz5wDtclRjZamNFm5eEcFFfp4OmuxF1XxuGZFcdxpMGGpLZhqdggbyncuCsFGEyi1LsypW841p7Il3pG9meWSe89s6QG/7fCMnR53xf78c6tAzFtQARO5WkRpvHAWxvPAAA2NJgVdiynAsLeLFTpjBjYNQCHssrwV2oJ/kotQbXOiIpaI64dEIFuIT6Y+80B3De6m1RID1jqi347kttoKvuBzDJc3cKlGtoaww0RkRMlhGtw8JlJ8GijlXn/1sQmqG5KhcN085YYHheEW4dGw8/LHU9NTjjvnlg2/l7umDYgAqIoOmyJAVhCg02Ypj4ExYf4oE9kfQ/W+sfGwGQWGy1Wd3WfMKm3oneERhr2atiLoHJT4JUbB+C19cm4ZkAk7hgRIy3g2D/Kr9Gqw7bXtu07ZhumAix7ki1ecwrHc7T4dEcGymv0eG+zZV+x7SlFKK3WI9BbhV1pJSir0eOI3SyoPRml2HSqUCqUtunib1mt2RYcR8YHSb1cx3O0WHs8D2bR8udoG5aKC65v0z+u6oEvdp5FgLcKs0fGYmC0P9aeyMfhrHKYzaJUXOzprkStwVJ/FeyjRnGVDk//chRGsxmPfH8YHu4K1Bkss80a1g9/uycL31q/V7spHELm17uzAAB7M0owsXcYzhRU4ZW1p3HdFZHSDMP/W3ncoXbLVmd2IKsMk/qEYcXhHEzpGwFPlXwLNzLcEBE52cUUespFqRDw8k0XF4gEQcAHtzUeLmvIS+Umbbxq2x/MxlZ31FB0oBf6d/HDsZwKzE6KOe/QyMjuwfi1e9N1PQ3ZBysADjVRgd4qXDsgEr8cynEYBnJTCDCaRWw6VYAwjQfuWrYPJrMIX+ufq4/aDVU6IxavOdXo9ab0C8enOzKk6e5je4WgR6gPPNwVqNIZ8eDXBwEAj0zoIdX62A8r3jQ4Cg9P6CH9bDSZ4a1SolJnxPbUYmkY8eWb+uO5307A39MdK+aNwg0f7kRGcTWe/PEoAEjBxl6Qt0ra7NRNISAu2BsphVXIq6iDj9oNNw7qgnUn8lFRa0CBVocfrUXlxVV6PLfyBE7lV+LaARFYcyzP4Xmv7hOGNcfzsTejFDtSi/HYD0fwuv8ZbHlinGzbb7CgmIiInK5vpAYKAY2Gts7nnVuvwKs3DZC2sHCGcI2H1Ftz2/CueHBcvMPjL93YH//+WwISo/0xpmcIXp+RiLnjLbVHX+w6i3nfHJTqVWyrLz860RI+zlkLlG2z1bxUSlxvN2PIz9MdV/cJh5tSgfgQx56udzalwFYG08uufiqywZYobkoFrhlgWUX70e8t+7DFBHnh2gGR2PbkeKx+ZDT8vVS4e1QsAMs2Dp7uStx7ZRyuGRCBsT1DpOcaYbfdyd1XxuHLe4ZJheM3DOyCRdP7Yc+/J2JqvwjpuWy+35eNI9nleOGPUzA36Am6b0w3KBUCDmWV4+mfjwEAJvUJk3VfsY7/zwsiIrrsfHznEBRX6RET1PyO8g11C/FBtwYh4FIJgoCfHkqy9iI1fm4PdyXuHxOP+8fUh56TuZZVom2btSaE+0prF4VrPHBnUiw+2pYuzU57ZEIP/O/PNFzZPRj9o/yw9YlxMJjMiA70knqq+kZqpEX+/jmpJ97cYKmH8VW74cruwXjxhn7oHaFpssdq1oiu+GF/trSX2X2ju0GhEBzWF7ppcBReX38GFbUGzBreFf93TR8AlhoiW2HzkJgAFGrrUGsw4ZEJPeCtdsMHtw3Ct3uyMN862wywDJn9ap2JNaJbIA5klsFgEqXhLwB4/vp+eGN9Mrr4e2JgtKXm6+vdWcgpr4XaTYG5DUJke2O4ISIip/P1cIfvRawm3ZZCfT1wgQWwHfSO8EVcsDcyiqsxtV84Xp+RiHu/2I9d6SXoH+UHlZsCM4dFS/U54xNCcfuI+nWFbCtQ25s3vjsq64y4f0w3DOwagL8PjsKKwznoFuwNQRAwy25dooYGRPlLQ3ZB3ippnzV7Xio3vHhDP6w9no954+uDyoAu9cNwXfw98eODIx12Hx/TMwRj7Hp3AGB0j2Bp6G3W8BjcMSIWWaU1uDMpBk/+dARuCgVmDeuK6wZEQu2ugCAIeGRCT/x6MAfVehNuHxHjtHV0WksQO9qayW1Mq9XCz88PFRUV0GhaN02TiIhcW3pRFdKKqjGxdygEQcDRc+V4ZsVxPDUlAaO6ByOvohZXv/knIvw9sO7RMS2ePt1a607k48GvD2DR9H64Y0TzQaihiloDEv+7HgCw6h9Xol+XxmsrNeX3I7k4mFWGf/+tN9yVLRteWn0sD+tP5GPhdX3h76W68AUX6WI+vxluiIiIWqFQWwe1m/KitvO4FCaz2KrlBZ748QjSiqrww/1JstbBXKqL+fzmsBQREVErtPfQS2vXTXp9RqKTW9LxXb4RjoiIiKgJDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC7FTe4GtDdRFAEAWq1W5pYQERFRS9k+t22f4+fT6cJNZWUlACA6OlrmlhAREdHFqqyshJ+f33nPEcSWRCAXYjabkZubC19fXwiC4NTn1mq1iI6ORnZ2NjQajVOf21XwHp0f78+F8R5dGO/R+fH+XFhHvEeiKKKyshKRkZFQKM5fVdPpem4UCgWioqLa9DU0Gk2H+WXoqHiPzo/358J4jy6M9+j8eH8urKPdowv12NiwoJiIiIhcCsMNERERuRSGGydSq9V47rnnoFar5W5Kh8V7dH68PxfGe3RhvEfnx/tzYZf7Pep0BcVERETk2thzQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdO8sEHHyA2NhYeHh4YPnw49u7dK3eTZLNw4UIIguDwlZCQID1eV1eHefPmISgoCD4+PrjppptQUFAgY4vb3p9//olrr70WkZGREAQBK1ascHhcFEU8++yziIiIgKenJyZOnIiUlBSHc0pLSzFr1ixoNBr4+/vjnnvuQVVVVTu+i7ZzofszZ86cRr9TU6ZMcTjHle8PACxevBhDhw6Fr68vQkNDcf311yM5OdnhnJb83crKysK0adPg5eWF0NBQPPnkkzAaje35VtpES+7PuHHjGv0ePfjggw7nuOr9AYAlS5ZgwIAB0sJ8SUlJWLNmjfS4K/3+MNw4wQ8//IB//vOfeO6553Dw4EEkJiZi8uTJKCwslLtpsunbty/y8vKkrx07dkiPPfbYY/j999/x448/Ytu2bcjNzcWNN94oY2vbXnV1NRITE/HBBx80+firr76Kd999Fx999BH27NkDb29vTJ48GXV1ddI5s2bNwokTJ7BhwwasWrUKf/75J+6///72egtt6kL3BwCmTJni8Dv13XffOTzuyvcHALZt24Z58+Zh9+7d2LBhAwwGA66++mpUV1dL51zo75bJZMK0adOg1+uxc+dOfPHFF1i2bBmeffZZOd6SU7Xk/gDAfffd5/B79Oqrr0qPufL9AYCoqCi8/PLLOHDgAPbv34+rrroK06dPx4kTJwC42O+PSJds2LBh4rx586SfTSaTGBkZKS5evFjGVsnnueeeExMTE5t8rLy8XHR3dxd//PFH6dipU6dEAOKuXbvaqYXyAiD++uuv0s9ms1kMDw8XX3vtNelYeXm5qFarxe+++04URVE8efKkCEDct2+fdM6aNWtEQRDEnJycdmt7e2h4f0RRFGfPni1Onz692Ws60/2xKSwsFAGI27ZtE0WxZX+3Vq9eLSoUCjE/P186Z8mSJaJGoxF1Ol37voE21vD+iKIojh07VnzkkUeavaYz3R+bgIAA8ZNPPnG53x/23FwivV6PAwcOYOLEidIxhUKBiRMnYteuXTK2TF4pKSmIjIxEt27dMGvWLGRlZQEADhw4AIPB4HC/EhIS0LVr1057vzIyMpCfn+9wT/z8/DB8+HDpnuzatQv+/v4YMmSIdM7EiROhUCiwZ8+edm+zHLZu3YrQ0FD06tULDz30EEpKSqTHOuP9qaioAAAEBgYCaNnfrV27dqF///4ICwuTzpk8eTK0Wq30r3dX0fD+2HzzzTcIDg5Gv379sGDBAtTU1EiPdab7YzKZ8P3336O6uhpJSUku9/vT6TbOdLbi4mKYTCaHP2wACAsLw+nTp2VqlbyGDx+OZcuWoVevXsjLy8N///tfjB49GsePH0d+fj5UKhX8/f0drgkLC0N+fr48DZaZ7X039Ttkeyw/Px+hoaEOj7u5uSEwMLBT3LcpU6bgxhtvRFxcHNLS0vDvf/8bU6dOxa5du6BUKjvd/TGbzXj00UcxatQo9OvXDwBa9HcrPz+/yd8z22Ouoqn7AwC33XYbYmJiEBkZiaNHj+Jf//oXkpOT8csvvwDoHPfn2LFjSEpKQl1dHXx8fPDrr7+iT58+OHz4sEv9/jDckNNNnTpV+n7AgAEYPnw4YmJisHz5cnh6esrYMrpc3XrrrdL3/fv3x4ABAxAfH4+tW7diwoQJMrZMHvPmzcPx48cdatmoXnP3x74Gq3///oiIiMCECROQlpaG+Pj49m6mLHr16oXDhw+joqICP/30E2bPno1t27bJ3Syn47DUJQoODoZSqWxUUV5QUIDw8HCZWtWx+Pv7o2fPnkhNTUV4eDj0ej3Ky8sdzunM98v2vs/3OxQeHt6oQN1oNKK0tLRT3rdu3bohODgYqampADrX/Zk/fz5WrVqFLVu2ICoqSjrekr9b4eHhTf6e2R5zBc3dn6YMHz4cABx+j1z9/qhUKnTv3h2DBw/G4sWLkZiYiHfeecflfn8Ybi6RSqXC4MGDsWnTJumY2WzGpk2bkJSUJGPLOo6qqiqkpaUhIiICgwcPhru7u8P9Sk5ORlZWVqe9X3FxcQgPD3e4J1qtFnv27JHuSVJSEsrLy3HgwAHpnM2bN8NsNkv/g+5Mzp07h5KSEkRERADoHPdHFEXMnz8fv/76KzZv3oy4uDiHx1vydyspKQnHjh1zCIIbNmyARqNBnz592ueNtJEL3Z+mHD58GAAcfo9c9f40x2w2Q6fTud7vj9wVza7g+++/F9Vqtbhs2TLx5MmT4v333y/6+/s7VJR3Jo8//ri4detWMSMjQ/zrr7/EiRMnisHBwWJhYaEoiqL44IMPil27dhU3b94s7t+/X0xKShKTkpJkbnXbqqysFA8dOiQeOnRIBCC++eab4qFDh8TMzExRFEXx5ZdfFv39/cWVK1eKR48eFadPny7GxcWJtbW10nNMmTJFHDhwoLhnzx5xx44dYo8ePcSZM2fK9Zac6nz3p7KyUnziiSfEXbt2iRkZGeLGjRvFQYMGiT169BDr6uqk53Dl+yOKovjQQw+Jfn5+4tatW8W8vDzpq6amRjrnQn+3jEaj2K9fP/Hqq68WDx8+LK5du1YMCQkRFyxYIMdbcqoL3Z/U1FRx0aJF4v79+8WMjAxx5cqVYrdu3cQxY8ZIz+HK90cURfHpp58Wt23bJmZkZIhHjx4Vn376aVEQBHH9+vWiKLrW7w/DjZO89957YteuXUWVSiUOGzZM3L17t9xNks0tt9wiRkREiCqVSuzSpYt4yy23iKmpqdLjtbW14ty5c8WAgADRy8tLvOGGG8S8vDwZW9z2tmzZIgJo9DV79mxRFC3TwZ955hkxLCxMVKvV4oQJE8Tk5GSH5ygpKRFnzpwp+vj4iBqNRrzrrrvEyspKGd6N853v/tTU1IhXX321GBISIrq7u4sxMTHifffd1+gfD658f0RRbPL+ABA///xz6ZyW/N06e/asOHXqVNHT01MMDg4WH3/8cdFgMLTzu3G+C92frKwsccyYMWJgYKCoVqvF7t27i08++aRYUVHh8Dyuen9EURTvvvtuMSYmRlSpVGJISIg4YcIEKdiIomv9/giiKIrt109ERERE1LZYc0NEREQuheGGiIiIXArDDREREbkUhhsiIiJyKQw3RERE5FIYboiIiMilMNwQERGRS2G4IaJOJzY2Fm+//bbczSCiNsJwQ0Rtas6cObj++usBAOPGjcOjjz7abq+9bNky+Pv7Nzq+b98+hx2iici1uMndACKii6XX66FSqVp9fUhIiBNbQ0QdDXtuiKhdzJkzB9u2bcM777wDQRAgCALOnj0LADh+/DimTp0KHx8fhIWF4Y477kBxcbF07bhx4zB//nw8+uijCA4OxuTJkwEAb775Jvr37w9vb29ER0dj7ty5qKqqAgBs3boVd911FyoqKqTXW7hwIYDGw1JZWVmYPn06fHx8oNFocPPNN6OgoEB6fOHChbjiiivw1VdfITY2Fn5+frj11ltRWVnZtjeNiFqF4YaI2sU777yDpKQk3HfffcjLy0NeXh6io6NRXl6Oq666CgMHDsT+/fuxdu1aFBQU4Oabb3a4/osvvoBKpcJff/2Fjz76CACgUCjw7rvv4sSJE/jiiy+wefNmPPXUUwCAkSNH4u2334ZGo5Fe74knnmjULrPZjOnTp6O0tBTbtm3Dhg0bkJ6ejltuucXhvLS0NKxYsQKrVq3CqlWrsG3bNrz88sttdLeI6FJwWIqI2oWfnx9UKhW8vLwQHh4uHX///fcxcOBAvPTSS9Kxzz77DNHR0Thz5gx69uwJAOjRowdeffVVh+e0r9+JjY3FCy+8gAcffBAffvghVCoV/Pz8IAiCw+s1tGnTJhw7dgwZGRmIjo4GAHz55Zfo27cv9u3bh6FDhwKwhKBly5bB19cXAHDHHXdg06ZNePHFFy/txhCR07HnhohkdeTIEWzZsgU+Pj7SV0JCAgBLb4nN4MGDG127ceNGTJgwAV26dIGvry/uuOMOlJSUoKampsWvf+rUKURHR0vBBgD69OkDf39/nDp1SjoWGxsrBRsAiIiIQGFh4UW9VyJqH+y5ISJZVVVV4dprr8Urr7zS6LGIiAjpe29vb4fHzp49i2uuuQYPPfQQXnzxRQQGBmLHjh245557oNfr4eXl5dR2uru7O/wsCALMZrNTX4OInIPhhojajUqlgslkcjg2aNAg/Pzzz4iNjYWbW8v/l3TgwAGYzWa88cYbUCgsndDLly+/4Os11Lt3b2RnZyM7O1vqvTl58iTKy8vRp0+fFreHiDoODksRUbuJjY3Fnj17cPbsWRQXF8NsNmPevHkoLS3FzJkzsW/fPqSlpWHdunW46667zhtMunfvDoPBgPfeew/p6en46quvpEJj+9erqqrCpk2bUFxc3ORw1cSJE9G/f3/MmjULBw8exN69e3HnnXdi7NixGDJkiNPvARG1PYYbImo3TzzxBJRKJfr06YOQkBBkZWUhMjISf/31F0wmE66++mr0798fjz76KPz9/aUemaYkJibizTffxCuvvIJ+/frhm2++weLFix3OGTlyJB588EHccsstCAkJaVSQDFiGl1auXImAgACMGTMGEydORLdu3fDDDz84/f0TUfsQRFEU5W4EERERkbOw54aIiIhcCsMNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdERETkUv4fpb2UIZM9rwEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  18%|█▊        | 313/1729 [43:44<3:18:03,  8.39s/it, loss=4.6893]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "optimizer = torch.optim.AdamW([p for p in base_model.parameters() if p.requires_grad], lr=1e-3)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    base_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(zip(\n",
    "        random.sample(templated_dataset_A['train']['text'], len(templated_dataset_A['train']['text'])),\n",
    "        random.sample(templated_dataset_B['train']['text'], len(templated_dataset_B['train']['text'])),\n",
    "        random.sample(templated_dataset_C['train']['text'], len(templated_dataset_C['train']['text']))\n",
    "    ), \n",
    "    total=min([len(templated_dataset_A['train']['text']), len(templated_dataset_B['train']['text']), len(templated_dataset_C['train']['text'])]),\n",
    "    desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for i, (prompt_a, prompt_b, prompt_c) in enumerate(progress_bar):\n",
    "        loss = compute_ziplora_loss_for_lm(base_model, prompt_a, prompt_b, prompt_c)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "        losses.append(current_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': f'{current_loss:.4f}'})\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.clf()\n",
    "            plt.plot(losses)\n",
    "            plt.title(\"Training Loss\")\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.show()\n",
    "\n",
    "        if i > 550:\n",
    "            break\n",
    "    \n",
    "    avg_loss = total_loss / len(progress_bar)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4461cff-250f-4aaf-b638-294878be522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a new model instance with the same architecture as the base model\n",
    "new_model = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Iterate through all modules and update weights for ZipLoRALinearLayers\n",
    "for (name, module), (_, new_module) in tqdm(zip(base_model.named_modules(), new_model.named_modules()), \n",
    "                                            desc=\"Merging layers\"):\n",
    "    if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "        # Get the merged weight and bias\n",
    "        merged_weight = module.get_ziplora_weight()\n",
    "        merged_bias = module.get_ziplora_bias()\n",
    "        \n",
    "        # Update the weights and bias of the corresponding layer in the new model\n",
    "        new_module.weight.data = merged_weight\n",
    "        if merged_bias is not None:\n",
    "            new_module.bias.data = merged_bias\n",
    "            \n",
    "    if isinstance(module, ZipLoRATripleEmbedding):\n",
    "        merged_weight = module.get_ziplora_weight()\n",
    "        new_module.weight.data = merged_weight\n",
    "\n",
    "# Save the new model\n",
    "new_model.save_pretrained(\"/workspace/zip_merged-again\")\n",
    "tokenizer.save_pretrained(\"/workspace/zip_merged-again\")\n",
    "\n",
    "print(\"Merged model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
