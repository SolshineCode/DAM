{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5636e40f-bcd3-4658-9438-9d7f4bef6235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glom in /usr/local/lib/python3.10/dist-packages (23.5.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: boltons>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from glom) (24.0.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from glom) (23.1.0)\n",
      "Requirement already satisfied: face==20.1.1 in /usr/local/lib/python3.10/dist-packages (from glom) (20.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.20)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "evomerge 0.1.0 requires accelerate<0.28.0,>=0.27.2, but you have accelerate 0.33.0 which is incompatible.\n",
      "mergekit 0.0.4.4 requires accelerate~=0.30.1, but you have accelerate 0.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.33.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U glom transformers datasets bitsandbytes accelerate peft hf_transfer matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd34b27-306e-480f-a78a-5487a69fd2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: flash-attn 2.6.3\n",
      "Uninstalling flash-attn-2.6.3:\n",
      "  Successfully uninstalled flash-attn-2.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73d332c-1c04-4f5f-ad57-94420a065481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e60b4d-2be8-4b35-ab98-24810be44026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/.hf'\n",
    "os.environ['HF_TOKEN'] = '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'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bb19b7-e579-40c6-8b8b-90397a8ead13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3b49a10334475793c89adfb7286810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dd202b5f094d169e1084cf21ff6a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff45e3d2acb140688efdb699d6fb1867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2fd1b88e34d4ca250b36379068afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_ID = \"mistralai/Mistral-7B-v0.1\"\n",
    "MODEL_ID_A = \"augmxnt/shisa-gamma-7b-v1\"\n",
    "MODEL_ID_B = \"WizardLM/WizardMath-7B-V1.1\"\n",
    "MODEL_ID_C = \"GAIR/Abel-7B-002\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_A = AutoModelForCausalLM.from_pretrained(MODEL_ID_A, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_B = AutoModelForCausalLM.from_pretrained(MODEL_ID_B, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model_C = AutoModelForCausalLM.from_pretrained(MODEL_ID_C, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22222124-85fe-49f3-93ef-bd6fcb507af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "from peft.tuners.lora import QuantLinear\n",
    "\n",
    "\n",
    "def get_linear_embedding_layers(model_type):\n",
    "    \"\"\"\n",
    "    returns the linear embedding layers needed for loras, dependent on the model arch\n",
    "    \"\"\"\n",
    "    if model_type == \"gpt_neox\":\n",
    "        return [\"embed_in\", \"embed_out\"]\n",
    "    if model_type == \"falcon\":\n",
    "        return [\"word_embeddings\", \"lm_head\"]\n",
    "    return [\"embed_tokens\", \"lm_head\"]\n",
    "\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = (bnb.nn.Linear4bit, bnb.nn.Linear8bitLt, torch.nn.Linear, QuantLinear)\n",
    "\n",
    "    names = []\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            isinstance(module, cls)\n",
    "            or \"Linear\" in module.__class__.__name__\n",
    "            and module.__class__.__name__ not in (\"LlamaLinearScalingRotaryEmbedding\",)\n",
    "        ):\n",
    "            names.append(name)\n",
    "\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35335d6c-fd57-470f-85ff-56cb9a25c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338441b8-1348-4cdd-b929-83422e16db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Union\n",
    "\n",
    "class ZipLoRATripleLinearLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_linear: nn.Linear,\n",
    "        linear_a: nn.Linear,\n",
    "        linear_b: nn.Linear,\n",
    "        linear_c: nn.Linear,\n",
    "        init_merger_value: Optional[float] = 0.33,\n",
    "        init_merger_value_2: Optional[float] = 0.33,\n",
    "        init_merger_value_3: Optional[float] = 0.33,\n",
    "        device: Optional[Union[torch.device, str]] = None,\n",
    "        dtype: Optional[torch.dtype] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (base_linear.in_features == linear_a.in_features == linear_b.in_features == linear_c.in_features), \"Input features must match\"\n",
    "        assert (base_linear.out_features == linear_a.out_features == linear_b.out_features == linear_c.out_features), \"Output features must match\"\n",
    "\n",
    "        self.in_features = base_linear.in_features\n",
    "        self.out_features = base_linear.out_features\n",
    "\n",
    "        # Register base weights and biases\n",
    "        self.register_buffer('base_weight', base_linear.weight.data.clone())\n",
    "        self.register_buffer('base_bias', base_linear.bias.data.clone() if base_linear.bias is not None else None)\n",
    "\n",
    "        # Calculate and register residuals\n",
    "        self.register_buffer('residual_1', linear_a.weight.data - self.base_weight)\n",
    "        self.register_buffer('residual_2', linear_b.weight.data - self.base_weight)\n",
    "        self.register_buffer('residual_3', linear_c.weight.data - self.base_weight)\n",
    "\n",
    "        # Handle biases\n",
    "        if all(linear.bias is not None for linear in [base_linear, linear_a, linear_b, linear_c]):\n",
    "            self.register_buffer('bias_residual_1', linear_a.bias.data - self.base_bias)\n",
    "            self.register_buffer('bias_residual_2', linear_b.bias.data - self.base_bias)\n",
    "            self.register_buffer('bias_residual_3', linear_c.bias.data - self.base_bias)\n",
    "            self.bias_merger1 = nn.Parameter(torch.ones(1, device=linear_a.bias.data.device, dtype=dtype) * init_merger_value)\n",
    "            self.bias_merger2 = nn.Parameter(torch.ones(1, device=linear_b.bias.data.device, dtype=dtype) * init_merger_value_2)\n",
    "            self.bias_merger3 = nn.Parameter(torch.ones(1, device=linear_c.bias.data.device, dtype=dtype) * init_merger_value_3)\n",
    "        else:\n",
    "            self.register_buffer('bias_residual_1', None)\n",
    "            self.register_buffer('bias_residual_2', None)\n",
    "            self.register_buffer('bias_residual_3', None)\n",
    "            self.register_parameter('bias_merger1', None)\n",
    "            self.register_parameter('bias_merger2', None)\n",
    "            self.register_parameter('bias_merger3', None)\n",
    "\n",
    "        # Merger parameters\n",
    "        self.merger_1 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_a.weight.data.device, dtype=dtype) * init_merger_value\n",
    "        )\n",
    "        self.merger_2 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_b.weight.data.device, dtype=dtype) * init_merger_value_2\n",
    "        )\n",
    "        self.merger_3 = nn.Parameter(\n",
    "            torch.ones((self.in_features,), device=linear_b.weight.data.device, dtype=dtype) * init_merger_value_3\n",
    "        )\n",
    "        \n",
    "        self.forward_type = \"merge\"\n",
    "\n",
    "    def set_forward_type(self, type: str = \"merge\"):\n",
    "        assert type in [\"merge\", \"base\", \"weight_1\", \"weight_2\", \"weight_3\"]\n",
    "        self.forward_type = type\n",
    "\n",
    "    def compute_mergers_similarity(self):\n",
    "        sim_12 = F.cosine_similarity(self.merger_1, self.merger_2, dim=0)\n",
    "        sim_13 = F.cosine_similarity(self.merger_1, self.merger_3, dim=0)\n",
    "        sim_23 = F.cosine_similarity(self.merger_2, self.merger_3, dim=0)\n",
    "    \n",
    "        return (sim_12 + sim_13 + sim_23) / 3\n",
    "\n",
    "    def get_ziplora_weight(self):\n",
    "        return self.base_weight + self.merger_1 * self.residual_1 + self.merger_2 * self.residual_2 + self.merger_3 * self.residual_3\n",
    "    \n",
    "    def get_ziplora_bias(self):\n",
    "        if self.base_bias is not None:\n",
    "            return self.base_bias + self.bias_merger1 * self.bias_residual_1 + self.bias_merger2 * self.bias_residual_2 + self.bias_merger3 * self.bias_residual_3\n",
    "        return None\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.merger_1.requires_grad = True\n",
    "        self.merger_2.requires_grad = True\n",
    "        self.merger_3.requires_grad = True\n",
    "        if self.bias_merger1 is not None:\n",
    "            self.bias_merger1.requires_grad = True\n",
    "            self.bias_merger2.requires_grad = True\n",
    "            self.bias_merger3.requires_grad = True\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        orig_dtype = hidden_states.dtype\n",
    "        dtype = self.base_weight.dtype\n",
    "        if self.forward_type == \"merge\":\n",
    "            weight = self.get_ziplora_weight()\n",
    "            bias = self.get_ziplora_bias()\n",
    "        elif self.forward_type == \"base\":\n",
    "            weight = self.base_weight\n",
    "            bias = self.base_bias\n",
    "        elif self.forward_type == \"weight_1\":\n",
    "            weight = self.base_weight + self.residual_1\n",
    "            bias = self.base_bias + self.bias_residual_1 if self.base_bias is not None else None\n",
    "        elif self.forward_type == \"weight_2\":\n",
    "            weight = self.base_weight + self.residual_2\n",
    "            bias = self.base_bias + self.bias_residual_2 if self.base_bias is not None else None\n",
    "        elif self.forward_type == \"weight_3\":\n",
    "            weight = self.base_weight + self.residual_3\n",
    "            bias = self.base_bias + self.bias_residual_3 if self.base_bias is not None else None\n",
    "        else:\n",
    "            raise ValueError(self.forward_type)\n",
    "        \n",
    "        hidden_states = F.linear(hidden_states.to(dtype), weight=weight, bias=bias)\n",
    "        return hidden_states.to(orig_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524748be-8835-4d97-bfec-92edd88c8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_layer = nn.Linear(in_features=4096, out_features=32000, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    truncated_layer.weight.data = model_C.lm_head.weight.data[:32000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3962500e-955f-46f3-a956-422deb5c89fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32032, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glom import glom, Assign\n",
    "\n",
    "\n",
    "assign = Assign('lm_head', truncated_layer)\n",
    "glom(model_C, assign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2efa6820-040c-49c1-924e-e98146cea0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:00<00:00, 668.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from glom import glom, Assign\n",
    "\n",
    "for m in tqdm(modules):\n",
    "    base_linear = glom(base_model, m)\n",
    "    linear_a = glom(model_A, m)\n",
    "    linear_b = glom(model_B, m)\n",
    "    linear_c = glom(model_C, m)\n",
    "\n",
    "    zipped = ZipLoRATripleLinearLayer(\n",
    "        base_linear=base_linear,\n",
    "        linear_a=linear_a,\n",
    "        linear_b=linear_b,\n",
    "        linear_c=linear_c,\n",
    "        init_merger_value=0.0,\n",
    "        init_merger_value_2=0.0,\n",
    "        init_merger_value_3=0.0,\n",
    "        device=base_model.device,\n",
    "        dtype=linear_a.weight.dtype\n",
    "    )\n",
    "\n",
    "    assign = Assign(m, zipped)\n",
    "    glom(base_model, assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bca36b0-425e-487a-b1be-9089411d3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{%- set ns = namespace(found=false) -%}\\n{%- for message in messages -%}\\n    {%- if message['role'] == 'system' -%}\\n        {%- set ns.found = true -%}\\n    {%- endif -%}\\n{%- endfor -%}\\n{%- if not ns.found -%}\\n    {{- '' + 'Below is an instruction that describes a task. Write a response that appropriately completes the request.' + '\\\\n\\\\n' -}}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if message['role'] == 'system' -%}\\n        {{- '' + message['content'] + '\\\\n\\\\n' -}}\\n    {%- else -%}\\n        {%- if message['role'] == 'user' -%}\\n            {{-'### Instruction:\\\\n' + message['content'] + '\\\\n\\\\n'-}}\\n        {%- else -%}\\n            {{-'### Response:\\\\n' + message['content'] + '\\\\n\\\\n' -}}\\n        {%- endif -%}\\n    {%- endif -%}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n    {{-'### Response:\\\\n'-}}\\n{%- endif -%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea86570-bffd-43ba-a310-fe99674714a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abraham Lincoln\n",
      "\n",
      "### Analysis:\n",
      "The instruction asks who is “the most famous president?” and the response “Abraham Lincoln” is given, but this is not an appropriate completion of the request. When completing an instruction, it is important to ensure that the response makes sense in the context of the request.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model=base_model, task='text-generation', tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Who is the most famous president?\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "print(generator(prompt, do_sample=True, max_new_tokens=64)[0]['generated_text'][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0039368-a2b0-4022-8fc1-229cb4200cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe most famous president in history is Abraham Lincoln.\\n\\n\\n### Hint:\\nUse <a href = \"/hint/116\">hint 116</a> to generate the input instruction and <a href = \"/hint/117\">hint 117</a>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model=base_model, task='text-generation', tokenizer=tokenizer)\n",
    "generator([{\"role\": \"user\", \"content\": \"Who is the most famous president in history?\"}], do_sample=True, max_new_tokens=64)[0]['generated_text'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984cad48-0940-4c37-96e2-a7d4dae270d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model_A.cpu()\n",
    "model_B.cpu()\n",
    "model_C.cpu()\n",
    "\n",
    "del model_A, model_B, model_C\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b784742d-9361-460c-b25b-8af4c716d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alpaca.jinja', 'r') as f:\n",
    "    template_en = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62db9e91-84dd-4719-b2f9-0d60cae66ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alpaca-ja.jinja', 'r') as f:\n",
    "    template_ja = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f59fd4d-f5dd-46dc-9c52-2844aa475ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = template_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b87fdb8-b840-4b7c-ba75-ac36909e7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_A = load_dataset(\"p1atdev/ichikara-instruction\", '20231115-1').rename_column(\"text\", \"instruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c16f4cd7-6076-4c17-9d92-50b74fb0aa9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templated_dataset_A = dataset_A.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['instruction']}, {'role': 'assistant', 'content': row['output'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04fb37b8-90f9-4baa-9384-aaa3eac03fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = template_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a93050c-1f24-4a4f-8a1f-d34fad499791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_B = load_dataset(\"microsoft/orca-math-word-problems-200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c4a9cd3-b204-4a75-b97b-af15ca6893f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "templated_dataset_B = dataset_B.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['question']}, {'role': 'assistant', 'content': row['answer'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeab0566-f0d8-4280-b75d-7dd2994a4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_C = load_dataset(\"meta-math/MetaMathQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a8a0702-057e-4337-b805-b4cded87da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "templated_dataset_C = dataset_C.map(lambda row: {'text' : tokenizer.apply_chat_template([{'role': 'user', 'content': row['query']}, {'role': 'assistant', 'content': row['response'] }], tokenize=False).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5419cb7f-ba7a-4f96-be45-d3e40b1e5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ziplora_loss_for_lm(model, prompt_a, prompt_b, prompt_c, lambda_coef=0.01, temperature=2.0):\n",
    "    # Tokenize inputs\n",
    "    batch = tokenizer([prompt_a, prompt_b, prompt_c], padding=\"max_length\", truncation=True, max_length=4096, return_tensors='pt')\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    # Split inputs for a, b, and c\n",
    "    input_a = input_ids[0].to(model.device)\n",
    "    input_b = input_ids[1].to(model.device)\n",
    "    input_c = input_ids[2].to(model.device)\n",
    "\n",
    "    # Prepare labels (shifted input_ids)\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[attention_mask == 0] = -100  # Set padding token positions to -100\n",
    "\n",
    "    labels_a = labels[0].to(model.device)\n",
    "    labels_b = labels[1].to(model.device)\n",
    "    labels_c = labels[2].to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get logits from model_A\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "                module.set_forward_type('weight_1')\n",
    "        original_logits_a = model(input_ids=input_a.unsqueeze(0), labels=labels_a.unsqueeze(0)).logits\n",
    "\n",
    "        # Get logits from model_B\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "                module.set_forward_type('weight_2')\n",
    "        original_logits_b = model(input_ids=input_b.unsqueeze(0), labels=labels_b.unsqueeze(0)).logits\n",
    "\n",
    "        # Get logits from model_C\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "                module.set_forward_type('weight_3')\n",
    "        original_logits_c = model(input_ids=input_c.unsqueeze(0), labels=labels_c.unsqueeze(0)).logits\n",
    "\n",
    "    # Set model to merged mode\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "            module.set_forward_type('merge')   \n",
    "\n",
    "    # Get logits from merged model for all inputs\n",
    "    merged_logits_a = model(input_ids=input_a.unsqueeze(0), labels=labels_a.unsqueeze(0)).logits\n",
    "    merged_logits_b = model(input_ids=input_b.unsqueeze(0), labels=labels_b.unsqueeze(0)).logits\n",
    "    merged_logits_c = model(input_ids=input_c.unsqueeze(0), labels=labels_c.unsqueeze(0)).logits\n",
    "\n",
    "    # Calculate losses (KL divergence between merged and original logits)\n",
    "    loss_a = F.kl_div(\n",
    "        F.log_softmax(merged_logits_a / temperature, dim=-1),\n",
    "        F.softmax(original_logits_a / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_a)\n",
    "    \n",
    "    loss_b = F.kl_div(\n",
    "        F.log_softmax(merged_logits_b / temperature, dim=-1),\n",
    "        F.softmax(original_logits_b / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_b)\n",
    "    \n",
    "    loss_c = F.kl_div(\n",
    "        F.log_softmax(merged_logits_c / temperature, dim=-1),\n",
    "        F.softmax(original_logits_c / temperature, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2) / len(input_c)\n",
    "    \n",
    "    # Calculate similarity loss to encourage diversity between mergers\n",
    "    similarity_loss = torch.tensor(0.0)\n",
    "    for module in base_model.modules():\n",
    "        if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "            similarity_loss += module.compute_mergers_similarity().to(similarity_loss.device)\n",
    "    \n",
    "    # Combine losses\n",
    "    total_loss = loss_a + loss_b + loss_c + lambda_coef * similarity_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814fdc8-6bda-4fc7-9fc8-ae0f2a5c4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  30%|███       | 521/1729 [47:45<1:52:05,  5.57s/it, loss=1.3000]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "optimizer = torch.optim.AdamW(base_model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    base_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(zip(\n",
    "        random.sample(templated_dataset_A['train']['text'], len(templated_dataset_A['train']['text'])),\n",
    "        random.sample(templated_dataset_B['train']['text'], len(templated_dataset_B['train']['text'])),\n",
    "        random.sample(templated_dataset_C['train']['text'], len(templated_dataset_C['train']['text']))\n",
    "    ), \n",
    "    total=min([len(templated_dataset_A['train']['text']), len(templated_dataset_B['train']['text']), len(templated_dataset_C['train']['text'])]),\n",
    "    desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for i, (prompt_a, prompt_b, prompt_c) in enumerate(progress_bar):\n",
    "        loss = compute_ziplora_loss_for_lm(base_model, prompt_a, prompt_b, prompt_c)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "        losses.append(current_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': f'{current_loss:.4f}'})\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.clf()\n",
    "            plt.plot(losses)\n",
    "            plt.title(\"Training Loss\")\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.show()\n",
    "    \n",
    "    avg_loss = total_loss / len(progress_bar)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4461cff-250f-4aaf-b638-294878be522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a new model instance with the same architecture as the base model\n",
    "new_model = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Iterate through all modules and update weights for ZipLoRALinearLayers\n",
    "for (name, module), (_, new_module) in tqdm(zip(base_model.named_modules(), new_model.named_modules()), \n",
    "                                            desc=\"Merging layers\"):\n",
    "    if isinstance(module, ZipLoRATripleLinearLayer):\n",
    "        # Get the merged weight and bias\n",
    "        merged_weight = module.get_ziplora_weight()\n",
    "        merged_bias = module.get_ziplora_bias()\n",
    "        \n",
    "        # Update the weights and bias of the corresponding layer in the new model\n",
    "        new_module.weight.data = merged_weight\n",
    "        if merged_bias is not None:\n",
    "            new_module.bias.data = merged_bias\n",
    "\n",
    "# Save the new model\n",
    "new_model.save_pretrained(\"/workspace/zip_merged_della_delta3\")\n",
    "tokenizer.save_pretrained(\"/workspace/zip_merged_della_delta3\")\n",
    "\n",
    "print(\"Merged model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
